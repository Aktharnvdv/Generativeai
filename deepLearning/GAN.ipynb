{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchfile data\n",
        "!git clone https://github.com/zeusm9/Text-to-Photo-realistic-Image-Synthesis-with-Stacked-Generative-Adversarial-Networks.git\n",
        "%cd Text-to-Photo-realistic-Image-Synthesis-with-Stacked-Generative-Adversarial-Networks/code"
      ],
      "metadata": {
        "id": "y4A9SyiB9uFw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77a31eaa-e033-4e1a-d329-b19240ccec9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchfile in /usr/local/lib/python3.10/dist-packages (0.1.0)\n",
            "Requirement already satisfied: data in /usr/local/lib/python3.10/dist-packages (0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from data) (1.16.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from data) (4.4.2)\n",
            "Requirement already satisfied: funcsigs in /usr/local/lib/python3.10/dist-packages (from data) (1.0.2)\n",
            "Cloning into 'Text-to-Photo-realistic-Image-Synthesis-with-Stacked-Generative-Adversarial-Networks'...\n",
            "remote: Enumerating objects: 58, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 58 (delta 22), reused 45 (delta 14), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (58/58), 16.82 KiB | 8.41 MiB/s, done.\n",
            "Resolving deltas: 100% (22/22), done.\n",
            "/content/Text-to-Photo-realistic-Image-Synthesis-with-Stacked-Generative-Adversarial-Networks/code/Text-to-Photo-realistic-Image-Synthesis-with-Stacked-Generative-Adversarial-Networks/code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import torch, datetime, dateutil.tz\n",
        "import torchvision.transforms as transforms\n",
        "import config as cfg\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datasets import TextDataset\n",
        "from train import GANTrainer\n",
        "import torch.utils.data as data\n",
        "import os.path\n",
        "import PIL\n",
        "import pickle\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import config as cfg\n",
        "import os\n",
        "import torch\n",
        "import time\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torchfile\n",
        "import numpy as np\n",
        "import pickle\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from utils import mkdir_p\n",
        "from torch.autograd import Variable\n",
        "from torchvision.models.inception import inception_v3\n",
        "from scipy.stats import entropy\n",
        "from torch.nn import functional as F\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import config as cfg\n",
        "from model import Stage1_G, Stage1_D\n",
        "from utils import weights_init, discriminator_loss, generator_loss, KL_loss, save_img_results, save_model"
      ],
      "metadata": {
        "id": "cje9tqEzm3OI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomDataset(Dataset):\n",
        "    def __init__(self, data_size, embedding_size):\n",
        "        self.data_size = data_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.random_images = torch.randn(self.data_size, 3, 64, 64)\n",
        "        self.random_embeddings = torch.randn(self.data_size,\n",
        "                                             self.embedding_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {'real_img_cpu': self.random_images[idx],\n",
        "                'txt_embedding': self.random_embeddings[idx]}\n",
        "\n",
        "random_dataset = RandomDataset(data_size=1000, embedding_size=4800)\n",
        "batch_size = 32\n",
        "data_loader = DataLoader(dataset=random_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "faAF7hz2xwUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GANTrainer(object):\n",
        "    def __init__(self, output_dir):\n",
        "        if cfg.TRAIN_FLAG:\n",
        "            self.model_dir = os.path.join(output_dir, 'Model')\n",
        "            self.image_dir = os.path.join(output_dir, 'Image')\n",
        "            self.log_dir = os.path.join(output_dir, 'Log')\n",
        "            mkdir_p(self.model_dir)\n",
        "            mkdir_p(self.image_dir)\n",
        "            mkdir_p(self.log_dir)\n",
        "\n",
        "        self.gpus = [0]\n",
        "        self.max_epoch = cfg.TRAIN_MAX_EPOCH\n",
        "        self.snapshot_interval = cfg.TRAIN_SNAPSHOT_INTERVAL\n",
        "        self.batch_size = cfg.TRAIN_BATCH_SIZE\n",
        "        torch.cuda.device(0)\n",
        "        cudnn.benchmark = True\n",
        "\n",
        "    def get_imgs(self):\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(32),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "        ])\n",
        "        imgs = []\n",
        "        for i in range(0, 2911):\n",
        "            img = Image.open(\"../data/birds/models/netG_epoch_360/\" + str(i) + \".png\").convert('RGB')\n",
        "            load_size = int(cfg.IMSIZE * 76 / 64)\n",
        "            img = img.resize((load_size, load_size), PIL.Image.BILINEAR)\n",
        "            img = transform(img)\n",
        "            img = np.array(img)\n",
        "            imgs.append(img)\n",
        "        return imgs\n",
        "\n",
        "    def load_network_stageI(self):\n",
        "        netG = Stage1_G()\n",
        "        netG.apply(weights_init)\n",
        "        print(netG)\n",
        "        netD = Stage1_D()\n",
        "        netD.apply(weights_init)\n",
        "        print(netD)\n",
        "\n",
        "        if cfg.NET_G != '':\n",
        "            state_dict = torch.load(cfg.NET_G, map_location=lambda storage, loc: storage)\n",
        "            netG.load_state_dict(state_dict)\n",
        "            print('Load from: ', cfg.NET_G)\n",
        "        if cfg.NET_D != '':\n",
        "            state_dict = torch.load(cfg.NET_D, map_location=lambda storage, loc: storage)\n",
        "            netD.load_state_dict(state_dict)\n",
        "            print('Load from: ', cfg.NET_D)\n",
        "\n",
        "        if cfg.CUDA:\n",
        "            netG.cuda()\n",
        "            netD.cuda()\n",
        "        return netG, netD\n",
        "\n",
        "    def load_network_stageII(self):\n",
        "        from model import Stage1_G, Stage2_G, Stage2_D\n",
        "        Stage1_G = Stage1_G()\n",
        "        netG = Stage2_G(Stage1_G)\n",
        "        netG.apply(weights_init)\n",
        "        print(netG)\n",
        "        if cfg.NET_G != '':\n",
        "            state_dict = torch.load(cfg.NET_G,\n",
        "                                    map_location=lambda storage, loc: storage)\n",
        "            netG.load_state_dict(state_dict)\n",
        "            print('Load from: ', cfg.NET_G)\n",
        "        elif cfg.STAGE1_G != '':\n",
        "            state_dict = torch.load(cfg.STAGE1_G,\n",
        "                                    map_location=lambda storage, loc: storage)\n",
        "            netG.Stage1_G.load_state_dict(state_dict)\n",
        "            print('Load from: ', cfg.STAGE1_G)\n",
        "        else:\n",
        "            print(\"Please give the Stage1_G path\")\n",
        "            return\n",
        "\n",
        "        netD = Stage2_D()\n",
        "        netD.apply(weights_init)\n",
        "        if cfg.NET_D != '':\n",
        "            state_dict = \\\n",
        "                torch.load(cfg.NET_D,\n",
        "                           map_location=lambda storage, loc: storage)\n",
        "            netD.load_state_dict(state_dict)\n",
        "            print('Load from: ', cfg.NET_D)\n",
        "        print(netD)\n",
        "\n",
        "        if cfg.CUDA:\n",
        "            netG.cuda()\n",
        "            netD.cuda()\n",
        "        return netG, netD\n",
        "\n",
        "    def train(self, data_loader, stage=1):\n",
        "        if stage == 1:\n",
        "            netG, netD = self.load_network_stageI()\n",
        "        else:\n",
        "            netG, netD = self.load_network_stageII()\n",
        "\n",
        "        nz = cfg.Z_DIM\n",
        "        batch_size = self.batch_size\n",
        "        noise = Variable(torch.FloatTensor(batch_size, nz))\n",
        "        fixed_noise = Variable(torch.FloatTensor(batch_size, nz).normal_(0, 1), requires_grad=True)\n",
        "        real_labels = Variable(torch.FloatTensor(batch_size).fill_(1))\n",
        "        fake_labels = Variable(torch.FloatTensor(batch_size).fill_(0))\n",
        "\n",
        "        if cfg.CUDA:\n",
        "            noise, fixed_noise = noise.cuda(), fixed_noise.cuda()\n",
        "            real_labels, fake_labels = real_labels.cuda(), fake_labels.cuda()\n",
        "\n",
        "        generator_lr = cfg.TRAIN_GENERATOR_LR\n",
        "        discriminator_lr = cfg.TRAIN_DISCRIMINATOR_LR\n",
        "        lr_decay_step = cfg.TRAIN_LR_DECAY_EPOCH\n",
        "        optimizerD = optim.Adam(netD.parameters(), lr=cfg.TRAIN_DISCRIMINATOR_LR, betas=(0.5, 0.999))\n",
        "\n",
        "        netG_para = []\n",
        "        for p in netG.parameters():\n",
        "            if p.requires_grad:\n",
        "                netG_para.append(p)\n",
        "        optimizerG = optim.Adam(netG_para, lr=cfg.TRAIN_GENERATOR_LR, betas=(0.5, 0.999))\n",
        "\n",
        "        count = 0\n",
        "        for epoch in range(self.max_epoch):\n",
        "            start_t = time.time()\n",
        "            if epoch % lr_decay_step == 0 and epoch > 0:\n",
        "                generator_lr *= 0.5\n",
        "                for param_group in optimizerG.param_groups:\n",
        "                    param_group['lr'] = generator_lr\n",
        "                discriminator_lr *= 0.5\n",
        "                for param_group in optimizerD.param_groups:\n",
        "                    param_group['lr'] = discriminator_lr\n",
        "            for i, data in enumerate(data_loader, 0):\n",
        "                # Prepare training data\n",
        "                real_img_cpu, txt_embedding = data\n",
        "                real_imgs = Variable(real_img_cpu)\n",
        "                txt_embedding = Variable(txt_embedding)\n",
        "                if cfg.CUDA:\n",
        "                    real_imgs = real_imgs.cuda()\n",
        "                    txt_embedding = txt_embedding.cuda()\n",
        "                # Generate fake images\n",
        "                noise.data.normal_(0, 1)\n",
        "                inputs = (txt_embedding, noise)\n",
        "                _, fake_imgs, mu, logvar = nn.parallel.data_parallel(netG, inputs, self.gpus)\n",
        "\n",
        "                # Update D network\n",
        "\n",
        "                netD.zero_grad()\n",
        "                errD, errD_real, errD_wrong, errD_fake = discriminator_loss(netD, real_imgs, fake_imgs,\n",
        "                                                                            real_labels, fake_labels, mu,\n",
        "                                                                            self.gpus)\n",
        "                errD.backward()\n",
        "                optimizerD.step()\n",
        "                ############################\n",
        "                # (2) Update G network\n",
        "                ###########################\n",
        "                netG.zero_grad()\n",
        "                errG = generator_loss(netD, fake_imgs,\n",
        "                                      real_labels, mu, self.gpus)\n",
        "                kl_loss = KL_loss(mu, logvar)\n",
        "                errG_total = errG + kl_loss * cfg.TRAIN_COEFF_KL\n",
        "                errG_total.backward()\n",
        "                optimizerG.step()\n",
        "\n",
        "                count = count + 1\n",
        "\n",
        "                if i % 100 == 0:\n",
        "\n",
        "                    # save the image result for each epoch\n",
        "                    inputs = (txt_embedding, fixed_noise)\n",
        "                    lr_fake, fake, _, _ = \\\n",
        "                        nn.parallel.data_parallel(netG, inputs, self.gpus)\n",
        "                    save_img_results(real_img_cpu, fake, epoch, self.image_dir)\n",
        "                    if lr_fake is not None:\n",
        "                        save_img_results(None, lr_fake, epoch, self.image_dir)\n",
        "                end_t = time.time()\n",
        "                print('''[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f Loss_KL: %.4f\n",
        "                                     Loss_real: %.4f Loss_wrong:%.4f Loss_fake %.4f\n",
        "                                     Total Time: %.2fsec\n",
        "                                  '''\n",
        "                      % (epoch, self.max_epoch, i, len(data_loader),\n",
        "                         errD.data, errG.data, kl_loss.data,\n",
        "                         errD_real, errD_wrong, errD_fake, (end_t - start_t)))\n",
        "                if epoch % self.snapshot_interval == 0:\n",
        "                    save_model(netG, netD, epoch, self.model_dir)\n",
        "                #\n",
        "            save_model(netG, netD, self.max_epoch, self.model_dir)\n",
        "\n",
        "    def inception_score(self, dataloader, cuda=True, batch_size=32, resize=False, splits=1):\n",
        "        \"\"\"Computes the inception score of the generated images imgs\n",
        "        imgs -- Torch dataset of (3xHxW) numpy images normalized in the range [-1, 1]\n",
        "        cuda -- whether or not to run on GPU\n",
        "        batch_size -- batch size for feeding into Inception v3\n",
        "        splits -- number of splits\n",
        "        \"\"\"\n",
        "\n",
        "        imgs = self.get_imgs()\n",
        "        N = 2912\n",
        "        # Set up dtype\n",
        "        if cuda:\n",
        "            dtype = torch.cuda.FloatTensor\n",
        "        else:\n",
        "            if torch.cuda.is_available():\n",
        "                print(\"WARNING: You have a CUDA device, so you should probably set cuda=True\")\n",
        "            dtype = torch.FloatTensor\n",
        "\n",
        "        dataloader = torch.utils.data.DataLoader(imgs, batch_size=batch_size)\n",
        "\n",
        "        # Load inception model\n",
        "        inception_model = inception_v3(pretrained=True, transform_input=False).type(dtype)\n",
        "        inception_model.eval()\n",
        "        up = nn.Upsample(size=(299, 299), mode='bilinear', align_corners=True).type(dtype)\n",
        "\n",
        "        def get_pred(x):\n",
        "            if resize:\n",
        "                x = up(x)\n",
        "            x = inception_model(x)\n",
        "            return F.softmax(x, dim=0).data.cpu().numpy()\n",
        "\n",
        "        # Get predictions\n",
        "        preds = np.zeros((N, 1000))\n",
        "\n",
        "        for i, batch in enumerate(dataloader, 0):\n",
        "            batch = batch.type(dtype)\n",
        "            batchv = Variable(batch)\n",
        "            batch_size_i = batch.size()[0]\n",
        "            preds[i * batch_size:i * batch_size + batch_size_i] = get_pred(batchv)\n",
        "\n",
        "        # Now compute the mean kl-div\n",
        "        split_scores = []\n",
        "\n",
        "        for k in range(splits):\n",
        "            part = preds[k * (N // splits): (k + 1) * (N // splits) - 1, :]\n",
        "            py = np.mean(part, axis=0)\n",
        "            scores = []\n",
        "            for i in range(part.shape[0]):\n",
        "                pyx = part[i, :]\n",
        "                ent = entropy(pyx, py)\n",
        "                scores.append(ent)\n",
        "            split_scores.append(np.exp(np.mean(scores)))\n",
        "\n",
        "        return np.mean(split_scores), np.std(split_scores)\n",
        "\n",
        "    def sample(self, data_loader, stage=1):\n",
        "        if stage == 1:\n",
        "            netG, _ = self.load_network_stageI()\n",
        "        else:\n",
        "            netG, _ = self.load_network_stageII()\n",
        "        netG.eval()\n",
        "\n",
        "        # path to save generated samples\n",
        "        save_dir = cfg.NET_G[:cfg.NET_G.find('.pth')]\n",
        "        if not os.path.isdir(save_dir):\n",
        "            mkdir_p(save_dir)\n",
        "\n",
        "        nz = cfg.Z_DIM\n",
        "        batch_size = self.batch_size\n",
        "        noise = Variable(torch.FloatTensor(batch_size, nz))\n",
        "\n",
        "        count = 0\n",
        "        for i, data in enumerate(data_loader, 0):\n",
        "            real_img_cpu, txt_embedding = data\n",
        "            txt_embedding = Variable(txt_embedding)\n",
        "\n",
        "            if cfg.CUDA:\n",
        "                txt_embedding = txt_embedding.cuda()\n",
        "            noise.data.normal_(0, 1)\n",
        "            inputs = (txt_embedding, noise)\n",
        "            _, fake_imgs, mu, logvar = \\\n",
        "                nn.parallel.data_parallel(netG, inputs, self.gpus)\n",
        "            for i in range(batch_size):\n",
        "                save_name = '%s/%d.png' % (save_dir, count + i)\n",
        "                im = fake_imgs[i].data.cpu().numpy()\n",
        "                im = (im + 1.0) * 127.5\n",
        "                im = im.astype(np.uint8)\n",
        "                im = np.transpose(im, (1, 2, 0))\n",
        "                im = Image.fromarray(im)\n",
        "                im.save(save_name)\n",
        "            count += batch_size"
      ],
      "metadata": {
        "id": "RYpjUGMbzwGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"/content\"\n",
        "algo = GANTrainer(output_dir)\n",
        "algo.train(data_loader, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hGgzX6xkxt1r",
        "outputId": "64773ad6-2565-453b-acd8-eec1b8e96ce9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stage1_G(\n",
            "  (ca_net): Ca_Net(\n",
            "    (fc): Linear(in_features=1024, out_features=256, bias=True)\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=228, out_features=24576, bias=False)\n",
            "    (1): BatchNorm1d(24576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (upsample1): Sequential(\n",
            "    (0): Upsample(scale_factor=2.0, mode='nearest')\n",
            "    (1): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "  )\n",
            "  (upsample2): Sequential(\n",
            "    (0): Upsample(scale_factor=2.0, mode='nearest')\n",
            "    (1): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "  )\n",
            "  (upsample3): Sequential(\n",
            "    (0): Upsample(scale_factor=2.0, mode='nearest')\n",
            "    (1): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "  )\n",
            "  (upsample4): Sequential(\n",
            "    (0): Upsample(scale_factor=2.0, mode='nearest')\n",
            "    (1): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "  )\n",
            "  (img): Sequential(\n",
            "    (0): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): Tanh()\n",
            "  )\n",
            ")\n",
            "Stage1_D(\n",
            "  (encode_img): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(96, 192, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(192, 384, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Conv2d(384, 768, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (get_cond_logits): D_Logits(\n",
            "    (outlogits): Sequential(\n",
            "      (0): Conv2d(896, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (3): Conv2d(768, 1, kernel_size=(4, 4), stride=(4, 4))\n",
            "      (4): Sigmoid()\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-171d642ef151>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGANTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-86269e363f6d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_loader, stage)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mnetG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_network_stageI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mnetG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_network_stageII\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-86269e363f6d>\u001b[0m in \u001b[0;36mload_network_stageI\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCUDA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mnetG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mnetD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnetG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \"\"\"\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \"\"\"\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    }
  ]
}