{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EyrwRm_WLdeG",
    "outputId": "e90782a7-4681-499a-fcee-67af9323b292",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'GenerativeImage2Text'...\n",
      "remote: Enumerating objects: 160, done.\u001b[K\n",
      "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
      "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
      "remote: Total 160 (delta 44), reused 33 (delta 26), pack-reused 97\u001b[K\n",
      "Receiving objects: 100% (160/160), 501.71 KiB | 3.16 MiB/s, done.\n",
      "Resolving deltas: 100% (63/63), done.\n",
      "/workspace/GenerativeImage2Text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azfuse@ git+https://github.com/microsoft/azfuse.git (from -r requirements.txt (line 6))\n",
      "  Cloning https://github.com/microsoft/azfuse.git to /tmp/pip-install-t3dj47vb/azfuse_4c60889b673442eaa818efb2cdd23342\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/microsoft/azfuse.git /tmp/pip-install-t3dj47vb/azfuse_4c60889b673442eaa818efb2cdd23342\n",
      "  Resolved https://github.com/microsoft/azfuse.git to commit 3d2ff80d414e9a6cb6a4176d8c59eb70184ee31b\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pycocotools (from -r requirements.txt (line 1))\n",
      "  Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting pycocoevalcap (from -r requirements.txt (line 2))\n",
      "  Downloading pycocoevalcap-1.2-py3-none-any.whl (104.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm (from -r requirements.txt (line 3))\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (6.0.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.1.0+cu118)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.16.0+cu118)\n",
      "Collecting transformers (from -r requirements.txt (line 8))\n",
      "  Downloading transformers-4.38.1-py3-none-any.whl.metadata (131 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting boto3 (from -r requirements.txt (line 9))\n",
      "  Downloading boto3-1.34.49-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting matplotlib>=2.1.0 (from pycocotools->-r requirements.txt (line 1))\n",
      "  Downloading matplotlib-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools->-r requirements.txt (line 1)) (1.24.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (2023.4.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (2.1.0)\n",
      "Collecting azure-storage-blob (from azfuse@ git+https://github.com/microsoft/azfuse.git->-r requirements.txt (line 6))\n",
      "  Downloading azure_storage_blob-12.19.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting deprecated (from azfuse@ git+https://github.com/microsoft/azfuse.git->-r requirements.txt (line 6))\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from azfuse@ git+https://github.com/microsoft/azfuse.git->-r requirements.txt (line 6)) (5.9.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 7)) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 7)) (9.3.0)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers->-r requirements.txt (line 8))\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 8)) (23.2)\n",
      "Collecting regex!=2019.12.17 (from transformers->-r requirements.txt (line 8))\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.19,>=0.14 (from transformers->-r requirements.txt (line 8))\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers->-r requirements.txt (line 8))\n",
      "  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting botocore<1.35.0,>=1.34.49 (from boto3->-r requirements.txt (line 9))\n",
      "  Downloading botocore-1.34.49-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->-r requirements.txt (line 9))\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->-r requirements.txt (line 9))\n",
      "  Downloading s3transfer-0.10.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.49->boto3->-r requirements.txt (line 9)) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.49->boto3->-r requirements.txt (line 9)) (1.26.13)\n",
      "Collecting fsspec (from torch->-r requirements.txt (line 5))\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1))\n",
      "  Downloading contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1))\n",
      "  Downloading fonttools-4.49.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (159 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.1/159.1 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1))\n",
      "  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1)) (2.4.7)\n",
      "Collecting azure-core<2.0.0,>=1.28.0 (from azure-storage-blob->azfuse@ git+https://github.com/microsoft/azfuse.git->-r requirements.txt (line 6))\n",
      "  Downloading azure_core-1.30.0-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /usr/lib/python3/dist-packages (from azure-storage-blob->azfuse@ git+https://github.com/microsoft/azfuse.git->-r requirements.txt (line 6)) (3.4.8)\n",
      "Collecting isodate>=0.6.1 (from azure-storage-blob->azfuse@ git+https://github.com/microsoft/azfuse.git->-r requirements.txt (line 6))\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated->azfuse@ git+https://github.com/microsoft/azfuse.git->-r requirements.txt (line 6))\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 5)) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 7)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 7)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 7)) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /usr/lib/python3/dist-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob->azfuse@ git+https://github.com/microsoft/azfuse.git->-r requirements.txt (line 6)) (1.16.0)\n",
      "Collecting typing-extensions (from torch->-r requirements.txt (line 5))\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.2/426.2 kB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.38.1-py3-none-any.whl (8.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m150.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading boto3-1.34.49-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.34.49-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m150.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading matplotlib-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m152.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m121.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m118.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_storage_blob-12.19.0-py3-none-any.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading azure_core-1.30.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Downloading contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (310 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.7/310.7 kB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.49.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m118.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: azfuse\n",
      "  Building wheel for azfuse (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for azfuse: filename=azfuse-0.1-py3-none-any.whl size=19217 sha256=2c64e9a2fc029a6a80f6bb188d66096f9bb4e2bb7dcb5153871e1c0d1180142d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-1mad07ky/wheels/65/93/85/c58d017f4796af7b56ba47848a891bd909e56b1a6a02b1a97b\n",
      "Successfully built azfuse\n",
      "Installing collected packages: wrapt, typing-extensions, tqdm, safetensors, regex, kiwisolver, jmespath, isodate, fsspec, fonttools, cycler, contourpy, matplotlib, huggingface-hub, deprecated, botocore, azure-core, tokenizers, s3transfer, pycocotools, azure-storage-blob, transformers, pycocoevalcap, boto3, azfuse\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed azfuse-0.1 azure-core-1.30.0 azure-storage-blob-12.19.0 boto3-1.34.49 botocore-1.34.49 contourpy-1.2.0 cycler-0.12.1 deprecated-1.2.14 fonttools-4.49.0 fsspec-2024.2.0 huggingface-hub-0.20.3 isodate-0.6.1 jmespath-1.0.1 kiwisolver-1.4.5 matplotlib-3.8.3 pycocoevalcap-1.2 pycocotools-2.0.7 regex-2023.12.25 s3transfer-0.10.0 safetensors-0.4.2 tokenizers-0.15.2 tqdm-4.66.2 transformers-4.38.1 typing-extensions-4.10.0 wrapt-1.16.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "creating build/lib/generativeimage2text\n",
      "copying generativeimage2text/tsv_io.py -> build/lib/generativeimage2text\n",
      "copying generativeimage2text/trie_decoder.py -> build/lib/generativeimage2text\n",
      "copying generativeimage2text/train.py -> build/lib/generativeimage2text\n",
      "copying generativeimage2text/torch_common.py -> build/lib/generativeimage2text\n",
      "copying generativeimage2text/taxonomy.py -> build/lib/generativeimage2text\n",
      "copying generativeimage2text/process_image.py -> build/lib/generativeimage2text\n",
      "copying generativeimage2text/model.py -> build/lib/generativeimage2text\n",
      "copying generativeimage2text/inference.py -> build/lib/generativeimage2text\n",
      "copying generativeimage2text/data_prepare.py -> build/lib/generativeimage2text\n",
      "copying generativeimage2text/common.py -> build/lib/generativeimage2text\n",
      "copying generativeimage2text/__init__.py -> build/lib/generativeimage2text\n",
      "creating build/lib/generativeimage2text/layers\n",
      "copying generativeimage2text/layers/decoder.py -> build/lib/generativeimage2text/layers\n",
      "copying generativeimage2text/layers/__init__.py -> build/lib/generativeimage2text/layers\n",
      "creating build/lib/generativeimage2text/data_layer\n",
      "copying generativeimage2text/data_layer/transform.py -> build/lib/generativeimage2text/data_layer\n",
      "copying generativeimage2text/data_layer/builder.py -> build/lib/generativeimage2text/data_layer\n",
      "copying generativeimage2text/data_layer/__init__.py -> build/lib/generativeimage2text/data_layer\n",
      "creating build/lib/generativeimage2text/layers/bert\n",
      "copying generativeimage2text/layers/bert/modeling_utils.py -> build/lib/generativeimage2text/layers/bert\n",
      "copying generativeimage2text/layers/bert/modeling_bert.py -> build/lib/generativeimage2text/layers/bert\n",
      "copying generativeimage2text/layers/bert/file_utils.py -> build/lib/generativeimage2text/layers/bert\n",
      "copying generativeimage2text/layers/bert/activations.py -> build/lib/generativeimage2text/layers/bert\n",
      "copying generativeimage2text/layers/bert/__init__.py -> build/lib/generativeimage2text/layers/bert\n",
      "creating build/lib/generativeimage2text/layers/CLIP\n",
      "copying generativeimage2text/layers/CLIP/model.py -> build/lib/generativeimage2text/layers/CLIP\n",
      "copying generativeimage2text/layers/CLIP/clip.py -> build/lib/generativeimage2text/layers/CLIP\n",
      "copying generativeimage2text/layers/CLIP/__init__.py -> build/lib/generativeimage2text/layers/CLIP\n",
      "running develop\n",
      "/usr/local/lib/python3.10/dist-packages/setuptools/command/develop.py:40: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` and ``easy_install``.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  easy_install.initialize_options(self)\n",
      "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n",
      "running egg_info\n",
      "creating generativeimage2text.egg-info\n",
      "writing generativeimage2text.egg-info/PKG-INFO\n",
      "writing dependency_links to generativeimage2text.egg-info/dependency_links.txt\n",
      "writing requirements to generativeimage2text.egg-info/requires.txt\n",
      "writing top-level names to generativeimage2text.egg-info/top_level.txt\n",
      "writing manifest file 'generativeimage2text.egg-info/SOURCES.txt'\n",
      "reading manifest file 'generativeimage2text.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "adding license file 'LICENSE'\n",
      "writing manifest file 'generativeimage2text.egg-info/SOURCES.txt'\n",
      "running build_ext\n",
      "Creating /usr/local/lib/python3.10/dist-packages/generativeimage2text.egg-link (link to .)\n",
      "Adding generativeimage2text 0.1 to easy-install.pth file\n",
      "\n",
      "Installed /workspace/GenerativeImage2Text\n",
      "Processing dependencies for generativeimage2text==0.1\n",
      "Searching for boto3==1.34.49\n",
      "Best match: boto3 1.34.49\n",
      "Adding boto3 1.34.49 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for transformers==4.38.1\n",
      "Best match: transformers 4.38.1\n",
      "Adding transformers 4.38.1 to easy-install.pth file\n",
      "Installing transformers-cli script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for torchvision==0.16.0+cu118\n",
      "Best match: torchvision 0.16.0+cu118\n",
      "Adding torchvision 0.16.0+cu118 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for azfuse==0.1\n",
      "Best match: azfuse 0.1\n",
      "Adding azfuse 0.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for torch==2.1.0+cu118\n",
      "Best match: torch 2.1.0+cu118\n",
      "Adding torch 2.1.0+cu118 to easy-install.pth file\n",
      "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
      "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
      "Installing torchrun script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for PyYAML==6.0.1\n",
      "Best match: PyYAML 6.0.1\n",
      "Adding PyYAML 6.0.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for tqdm==4.66.2\n",
      "Best match: tqdm 4.66.2\n",
      "Adding tqdm 4.66.2 to easy-install.pth file\n",
      "Installing tqdm script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for pycocoevalcap==1.2\n",
      "Best match: pycocoevalcap 1.2\n",
      "Adding pycocoevalcap 1.2 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for pycocotools==2.0.7\n",
      "Best match: pycocotools 2.0.7\n",
      "Adding pycocotools 2.0.7 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for s3transfer==0.10.0\n",
      "Best match: s3transfer 0.10.0\n",
      "Adding s3transfer 0.10.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for jmespath==1.0.1\n",
      "Best match: jmespath 1.0.1\n",
      "Adding jmespath 1.0.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for botocore==1.34.49\n",
      "Best match: botocore 1.34.49\n",
      "Adding botocore 1.34.49 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for safetensors==0.4.2\n",
      "Best match: safetensors 0.4.2\n",
      "Adding safetensors 0.4.2 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for tokenizers==0.15.2\n",
      "Best match: tokenizers 0.15.2\n",
      "Adding tokenizers 0.15.2 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for requests==2.31.0\n",
      "Best match: requests 2.31.0\n",
      "Adding requests 2.31.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for regex==2023.12.25\n",
      "Best match: regex 2023.12.25\n",
      "Adding regex 2023.12.25 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for packaging==23.2\n",
      "Best match: packaging 23.2\n",
      "Adding packaging 23.2 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for numpy==1.24.1\n",
      "Best match: numpy 1.24.1\n",
      "Adding numpy 1.24.1 to easy-install.pth file\n",
      "Installing f2py script to /usr/local/bin\n",
      "Installing f2py3 script to /usr/local/bin\n",
      "Installing f2py3.10 script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for huggingface-hub==0.20.3\n",
      "Best match: huggingface-hub 0.20.3\n",
      "Adding huggingface-hub 0.20.3 to easy-install.pth file\n",
      "Installing huggingface-cli script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for filelock==3.9.0\n",
      "Best match: filelock 3.9.0\n",
      "Adding filelock 3.9.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for Pillow==9.3.0\n",
      "Best match: Pillow 9.3.0\n",
      "Adding Pillow 9.3.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for psutil==5.9.6\n",
      "Best match: psutil 5.9.6\n",
      "Adding psutil 5.9.6 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for Deprecated==1.2.14\n",
      "Best match: Deprecated 1.2.14\n",
      "Adding Deprecated 1.2.14 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for azure-storage-blob==12.19.0\n",
      "Best match: azure-storage-blob 12.19.0\n",
      "Adding azure-storage-blob 12.19.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for triton==2.1.0\n",
      "Best match: triton 2.1.0\n",
      "Adding triton 2.1.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for fsspec==2024.2.0\n",
      "Best match: fsspec 2024.2.0\n",
      "Adding fsspec 2024.2.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for Jinja2==3.1.2\n",
      "Best match: Jinja2 3.1.2\n",
      "Adding Jinja2 3.1.2 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for networkx==3.0\n",
      "Best match: networkx 3.0\n",
      "Adding networkx 3.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for sympy==1.12\n",
      "Best match: sympy 1.12\n",
      "Adding sympy 1.12 to easy-install.pth file\n",
      "Installing isympy script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for typing-extensions==4.10.0\n",
      "Best match: typing-extensions 4.10.0\n",
      "Adding typing-extensions 4.10.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for matplotlib==3.8.3\n",
      "Best match: matplotlib 3.8.3\n",
      "Adding matplotlib 3.8.3 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for urllib3==1.26.13\n",
      "Best match: urllib3 1.26.13\n",
      "Adding urllib3 1.26.13 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for python-dateutil==2.8.2\n",
      "Best match: python-dateutil 2.8.2\n",
      "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for certifi==2022.12.7\n",
      "Best match: certifi 2022.12.7\n",
      "Adding certifi 2022.12.7 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for idna==3.4\n",
      "Best match: idna 3.4\n",
      "Adding idna 3.4 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for charset-normalizer==2.1.1\n",
      "Best match: charset-normalizer 2.1.1\n",
      "Adding charset-normalizer 2.1.1 to easy-install.pth file\n",
      "Installing normalizer script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for wrapt==1.16.0\n",
      "Best match: wrapt 1.16.0\n",
      "Adding wrapt 1.16.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for isodate==0.6.1\n",
      "Best match: isodate 0.6.1\n",
      "Adding isodate 0.6.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for cryptography==3.4.8\n",
      "Best match: cryptography 3.4.8\n",
      "Adding cryptography 3.4.8 to easy-install.pth file\n",
      "\n",
      "Using /usr/lib/python3/dist-packages\n",
      "Searching for azure-core==1.30.0\n",
      "Best match: azure-core 1.30.0\n",
      "Adding azure-core 1.30.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for MarkupSafe==2.1.2\n",
      "Best match: MarkupSafe 2.1.2\n",
      "Adding MarkupSafe 2.1.2 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for mpmath==1.3.0\n",
      "Best match: mpmath 1.3.0\n",
      "Adding mpmath 1.3.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for pyparsing==2.4.7\n",
      "Best match: pyparsing 2.4.7\n",
      "Adding pyparsing 2.4.7 to easy-install.pth file\n",
      "\n",
      "Using /usr/lib/python3/dist-packages\n",
      "Searching for kiwisolver==1.4.5\n",
      "Best match: kiwisolver 1.4.5\n",
      "Adding kiwisolver 1.4.5 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for fonttools==4.49.0\n",
      "Best match: fonttools 4.49.0\n",
      "Adding fonttools 4.49.0 to easy-install.pth file\n",
      "Installing fonttools script to /usr/local/bin\n",
      "Installing pyftmerge script to /usr/local/bin\n",
      "Installing pyftsubset script to /usr/local/bin\n",
      "Installing ttx script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for cycler==0.12.1\n",
      "Best match: cycler 0.12.1\n",
      "Adding cycler 0.12.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for contourpy==1.2.0\n",
      "Best match: contourpy 1.2.0\n",
      "Adding contourpy 1.2.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for six==1.16.0\n",
      "Best match: six 1.16.0\n",
      "Adding six 1.16.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/lib/python3/dist-packages\n",
      "Finished processing dependencies for generativeimage2text==0.1\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/microsoft/GenerativeImage2Text.git\n",
    "%cd GenerativeImage2Text/generativeimage2text\n",
    "!pip install -r requirements.txt\n",
    "!python setup.py build develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "0h-ee6jd7i5K"
   },
   "outputs": [],
   "source": [
    "from common import Config\n",
    "import json\n",
    "import os.path as op\n",
    "from common import qd_tqdm as tqdm\n",
    "from common import json_dump\n",
    "from common import pilimg_from_base64\n",
    "from torch_common import recursive_to_device\n",
    "from tsv_io import TSVFile, tsv_writer, tsv_reader\n",
    "from common import write_to_file\n",
    "import torch\n",
    "import PIL\n",
    "from pprint import pformat\n",
    "import logging\n",
    "from transformers import BertTokenizer\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "from PIL import Image\n",
    "from azfuse import File\n",
    "\n",
    "from common import init_logging\n",
    "from common import parse_general_args\n",
    "from tsv_io import load_from_yaml_file\n",
    "from torch_common import torch_load\n",
    "from torch_common import load_state_dict\n",
    "from torch_common import resize_2d_pos_embed\n",
    "from layers.CLIP import clip\n",
    "from layers.decoder import (TransformerDecoderTextualHead,\n",
    "                             AutoRegressiveBeamSearch, GeneratorWithBeamSearch)\n",
    "from layers.decoder import CaptioningModel\n",
    "from process_image import load_image_by_pil\n",
    "from data_layer.transform import RenameKey, SelectTransform\n",
    "from data_layer.transform import ImageTransform2Dict\n",
    "from data_layer.transform import get_inception_train_transform\n",
    "from data_layer.builder import collate_fn\n",
    "from model import get_git_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "5jiPKVCm7fHi"
   },
   "outputs": [],
   "source": [
    "def get_data(image_file, prefix, target, tokenizer, image_transform):\n",
    "    max_text_len = 40\n",
    "    prefix_encoding = tokenizer(\n",
    "        prefix, padding='do_not_pad',\n",
    "        add_special_tokens=False,\n",
    "        truncation=True, max_length=max_text_len)\n",
    "    target_encoding = tokenizer(\n",
    "        target, padding='do_not_pad',\n",
    "        add_special_tokens=False,\n",
    "        truncation=True, max_length=max_text_len)\n",
    "    need_predict = [0] * len(prefix_encoding['input_ids']) + [1] * len(target_encoding['input_ids'])\n",
    "    payload = prefix_encoding['input_ids'] + target_encoding['input_ids']\n",
    "    if len(payload) > max_text_len:\n",
    "        payload = payload[-(max_text_len - 2):]\n",
    "        need_predict = need_predict[-(max_text_len - 2):]\n",
    "    input_ids = [tokenizer.cls_token_id] + payload + [tokenizer.sep_token_id]\n",
    "    need_predict = [0] + need_predict + [1]\n",
    "\n",
    "    im = load_image_by_pil(image_file)\n",
    "\n",
    "    data = {\n",
    "        'caption_tokens': torch.tensor(input_ids),\n",
    "        #'caption_lengths': len(input_ids),\n",
    "        'need_predict': torch.tensor(need_predict),\n",
    "        'image': im,\n",
    "        # 'rect' field can be fed in 'caption', which tells the bounding box\n",
    "        # region of the image that is described by the caption. In this case,\n",
    "        # we can optionally crop the region.\n",
    "        'caption': {},\n",
    "        # this iteration can be used for crop-size selection so that all GPUs\n",
    "        # can process the image with the same input size\n",
    "        'iteration': 0,\n",
    "    }\n",
    "    data = image_transform(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_image_transform(cfg):\n",
    "    return get_multi_scale_image_transform(cfg, is_train=True)\n",
    "\n",
    "def get_default_mean():\n",
    "    return [0.485, 0.456, 0.406]\n",
    "\n",
    "def get_default_std():\n",
    "    return [0.229, 0.224, 0.225]\n",
    "\n",
    "def get_transform_image_norm(cfg, default=None):\n",
    "    if cfg.data_normalize == 'default':\n",
    "        normalize = transforms.Normalize(\n",
    "            mean=get_default_mean(), std=get_default_std())\n",
    "    elif cfg.data_normalize == 'clip':\n",
    "        # clip model\n",
    "        normalize = transforms.Normalize(\n",
    "            (0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
    "    else:\n",
    "        raise NotImplementedError(cfg.data_normalize)\n",
    "    return normalize\n",
    "\n",
    "def get_transform_vit_default(cfg, is_train):\n",
    "    default_normalize = transforms.Normalize(\n",
    "            mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    normalize = get_transform_image_norm(cfg, default_normalize)\n",
    "    transform = get_inception_train_transform(\n",
    "        bgr2rgb=True,\n",
    "        crop_size=cfg.train_crop_size,\n",
    "        normalize=normalize,\n",
    "        small_scale=cfg.input_small_scale,\n",
    "        no_color_jitter=cfg.no_color_jitter,\n",
    "        no_flip=cfg.no_flip,\n",
    "        no_aspect_dist=cfg.no_aspect_dist,\n",
    "        resize_crop=cfg.resize_crop,\n",
    "        max_size=cfg.train_max_size,\n",
    "        interpolation=cfg.interpolation or Image.BILINEAR,\n",
    "    )\n",
    "    return transform\n",
    "\n",
    "def get_transform_image(cfg, is_train):\n",
    "    train_transform = cfg.train_transform\n",
    "    if train_transform == 'vitp':\n",
    "        transform = get_transform_vit_default(\n",
    "            cfg, is_train=is_train)\n",
    "    else:\n",
    "        raise NotImplementedError(train_transform)\n",
    "    return transform\n",
    "\n",
    "class ImageTransform2Images(object):\n",
    "    def __init__(self, sep_transform, first_joint=None):\n",
    "        self.image_transform = sep_transform\n",
    "        self.first_joint = first_joint\n",
    "\n",
    "    def __call__(self, imgs):\n",
    "        if self.first_joint is not None:\n",
    "            imgs = self.first_joint(imgs)\n",
    "        return [self.image_transform(im) for im in imgs]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'ImageTransform2Images(image_transform={})'.format(\n",
    "            self.image_transform,\n",
    "        )\n",
    "\n",
    "def get_transform_images(cfg, is_train):\n",
    "    trans = get_transform_image(cfg, is_train)\n",
    "    trans = ImageTransform2Images(trans)\n",
    "    return trans\n",
    "\n",
    "def trans_select_for_crop_size(\n",
    "    data, train_crop_sizes,\n",
    "    iteration_multi=0,\n",
    "):\n",
    "    if iteration_multi <= 0:\n",
    "        if len(train_crop_sizes) == 1:\n",
    "            idx = 0\n",
    "        else:\n",
    "            idx = data['iteration'] % len(train_crop_sizes)\n",
    "    elif data['iteration'] <= iteration_multi:\n",
    "        idx = data['iteration'] % len(train_crop_sizes)\n",
    "    else:\n",
    "        idx = -1\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-c CONFIG_FILE] [-p PARAM]\n",
      "                             [-bp BASE64_PARAM]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-cbec89a8-e7f8-4242-b9ae-78e698f0979c.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3556: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def get_multi_scale_image_transform(cfg, is_train, get_one=get_transform_image):\n",
    "    def get_multi_res_transform(s):\n",
    "        old = cfg.train_crop_size if is_train else cfg.test_crop_size\n",
    "        all_t = []\n",
    "        multi_res_factors = cfg.multi_res_factors or []\n",
    "        for i, f in enumerate(multi_res_factors):\n",
    "            if is_train:\n",
    "                cfg.train_crop_size = s // f\n",
    "            else:\n",
    "                cfg.test_crop_size = s // f\n",
    "            key = 'image_{}'.format(i)\n",
    "            all_t.append(RenameKey({'image': key}, not_delete_origin=True))\n",
    "            t = get_one(cfg, is_train)\n",
    "            t = ImageTransform2Dict(t, key=key)\n",
    "            all_t.append(t)\n",
    "        # get_one depends on train_crop_size\n",
    "        if is_train:\n",
    "            cfg.train_crop_size = s\n",
    "        else:\n",
    "            cfg.test_crop_size = s\n",
    "        t = get_one(cfg, is_train)\n",
    "        t = ImageTransform2Dict(t)\n",
    "        all_t.append(t)\n",
    "        if is_train:\n",
    "            cfg.train_crop_size = old\n",
    "        else:\n",
    "            cfg.test_crop_size = old\n",
    "        return transforms.Compose(all_t)\n",
    "\n",
    "    if is_train:\n",
    "        if cfg.min_size_range32 is None:\n",
    "            train_crop_sizes = [cfg.train_crop_size]\n",
    "        else:\n",
    "            train_crop_sizes = list(range(\n",
    "                cfg.min_size_range32[0],\n",
    "                cfg.min_size_range32[1] + cfg.patch_size - 1, cfg.patch_size,\n",
    "            ))\n",
    "    else:\n",
    "        train_crop_sizes = [cfg.test_crop_size]\n",
    "\n",
    "    crop_trans = []\n",
    "    for s in train_crop_sizes:\n",
    "        t = get_multi_res_transform(s)\n",
    "        crop_trans.append(t)\n",
    "    iteration_multi = 0\n",
    "    image_transform = SelectTransform(\n",
    "        crop_trans,\n",
    "        lambda d: trans_select_for_crop_size(\n",
    "            d, train_crop_sizes, iteration_multi))\n",
    "    return image_transform\n",
    "\n",
    "def forward_backward_example(image_files, captions, prefixs=None):\n",
    "    if prefixs is None:\n",
    "        prefixs = [''] * len(captions)\n",
    "    cfg = {\n",
    "        'crop_region_extend_in_datatransform': 4,\n",
    "        'data_normalize': 'clip',\n",
    "        'train_crop_size': 224,\n",
    "        'input_small_scale': 0.8,\n",
    "        'no_color_jitter': True,\n",
    "        'no_flip': True,\n",
    "        'no_aspect_dist': True,\n",
    "        'interpolation': 'bicubic',\n",
    "        'min_size_range32': [160, 224],\n",
    "        'patch_size': 16,\n",
    "        'train_transform': 'vitp',\n",
    "    }\n",
    "    cfg = Config(cfg, {})\n",
    "    all_data = []\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "    image_transform = get_image_transform(cfg)\n",
    "    for image_file, prefix, target in zip(image_files, prefixs, captions):\n",
    "        data = get_data(image_file, prefix, target,\n",
    "                        tokenizer, image_transform)\n",
    "        all_data.append(data)\n",
    "    data = collate_fn(all_data)\n",
    "    logging.info(image_transform)\n",
    "    data = recursive_to_device(data, 'cuda')\n",
    "\n",
    "    param = {}\n",
    "    model = get_git_model(tokenizer, param)\n",
    "    model.train()\n",
    "    model.cuda()\n",
    "    loss_dict = model(data)\n",
    "    loss = sum(loss_dict.values())\n",
    "    loss.backward()\n",
    "    logging.info(loss)\n",
    "\n",
    "def speed_test_forward_backward():\n",
    "    duplicate = 32\n",
    "    image_files = ['/workspace/GenerativeImage2Text/aux_data/images/1.jpg', '/workspace/GenerativeImage2Text/aux_data/images/2.jpg'] * duplicate\n",
    "    captions = ['a couple of boats in a large body of water.', 'a view of a mountain with a tree'] * duplicate\n",
    "\n",
    "    prefixs = [''] * len(captions)\n",
    "    cfg = {\n",
    "        'crop_region_extend_in_datatransform': 4,\n",
    "        'data_normalize': 'clip',\n",
    "        'train_crop_size': 224,\n",
    "        'input_small_scale': 0.8,\n",
    "        'no_color_jitter': True,\n",
    "        'no_flip': True,\n",
    "        'no_aspect_dist': True,\n",
    "        'interpolation': 'bicubic',\n",
    "        'min_size_range32': [160, 224],\n",
    "        'patch_size': 16,\n",
    "        'train_transform': 'vitp',\n",
    "    }\n",
    "    cfg = Config(cfg, {})\n",
    "    all_data = []\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "    image_transform = get_image_transform(cfg)\n",
    "    for image_file, prefix, target in zip(image_files, prefixs, captions):\n",
    "        data = get_data(image_file, prefix, target,\n",
    "                        tokenizer, image_transform)\n",
    "        all_data.append(data)\n",
    "    data = collate_fn(all_data)\n",
    "    logging.info(image_transform)\n",
    "    data = recursive_to_device(data, 'cuda')\n",
    "    data['image'] = data['image'].to(torch.float16)\n",
    "\n",
    "    param = {}\n",
    "    model = get_git_model(tokenizer, param)\n",
    "    model.train()\n",
    "    model.cuda()\n",
    "    model.half()\n",
    "\n",
    "    # warmup\n",
    "    for _ in range(2):\n",
    "        loss_dict = model(data)\n",
    "        loss = sum(loss_dict.values())\n",
    "        loss.backward()\n",
    "\n",
    "    import time\n",
    "    start = time.time()\n",
    "    for iteration in range(50000):\n",
    "        loss_dict = model(data)\n",
    "        loss = sum(loss_dict.values())\n",
    "        loss.backward()\n",
    "        if (iteration % 10) == 0:\n",
    "            end = time.time()\n",
    "            speed = data['image'].shape[0] * 100 / (end - start)\n",
    "            if iteration > 0:\n",
    "                logging.info('speed = {}'.format(speed))\n",
    "            start = time.time()\n",
    "\n",
    "    logging.info(loss)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    init_logging()\n",
    "    kwargs = parse_general_args()\n",
    "    logging.info('param:\\n{}'.format(pformat(kwargs)))\n",
    "    speed_test_forward_backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5RCkApMEVoyY",
    "outputId": "b0b6872d-5879-4ae1-bcd1-dff19ff3a8a2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# single image, captioning\n",
    "!AZFUSE_TSV_USE_FUSE=1 python -m generativeimage2text.inference -p \"{'type': 'test_git_inference_single_image', \\\n",
    "      'image_path': '/workspace/GenerativeImage2Text/aux_data/images/1.jpg', \\\n",
    "      'model_name': 'GIT_BASE', \\\n",
    "      'prefix': '', \\\n",
    "}\"\n",
    "# single image, question answering\n",
    "!AZFUSE_TSV_USE_FUSE=1 python -m generativeimage2text.inference -p \"{'type': 'test_git_inference_single_image', \\\n",
    "      'image_path': '/workspace/GenerativeImage2Text/aux_data/images/1.jpg', \\\n",
    "      'model_name': 'GIT_BASE_VQAv2', \\\n",
    "      'prefix': 'what is it?', \\\n",
    "}\"\n",
    "# multiple images, captioning\n",
    "!AZFUSE_TSV_USE_FUSE=1 python -m generativeimage2text.inference -p \"{'type': 'test_git_inference_single_image', \\\n",
    "      'image_path': ['/workspace/GenerativeImage2Text/aux_data/images/1.jpg', '/workspace/GenerativeImage2Text/aux_data/images/1.jpg', '/workspace/GenerativeImage2Text/aux_data/images/1.jpg', '/workspace/GenerativeImage2Text/aux_data/images/1.jpg', '/workspace/GenerativeImage2Text/aux_data/images/1.jpg', '/workspace/GenerativeImage2Text/aux_data/images/1.jpg'], \\\n",
    "      'model_name': 'GIT_BASE_VATEX', \\\n",
    "      'prefix': '', \\\n",
    "}\"\n",
    "# multiple images, question answering\n",
    "!AZFUSE_TSV_USE_FUSE=1 python -m generativeimage2text.inference -p \"{'type': 'test_git_inference_single_image', \\\n",
    "      'image_path': ['/workspace/GenerativeImage2Text/aux_data/images/1.jpg', '/workspace/GenerativeImage2Text/aux_data/images/1.jpg', '/workspace/GenerativeImage2Text/aux_data/images/1.jpg', '/workspace/GenerativeImage2Text/aux_data/images/1.jpg', '/workspace/GenerativeImage2Text/aux_data/images/1.jpg', '/workspace/GenerativeImage2Text/aux_data/images/1.jpg'], \\\n",
    "      'model_name': 'GIT_BASE_MSRVTT_QA', \\\n",
    "      'prefix': 'what is it?', \\\n",
    "}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
