{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EyrwRm_WLdeG",
    "outputId": "e90782a7-4681-499a-fcee-67af9323b292",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'GenerativeImage2Text'...\n",
      "remote: Enumerating objects: 160, done.\u001b[K\n",
      "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
      "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
      "remote: Total 160 (delta 44), reused 33 (delta 26), pack-reused 97\u001b[K\n",
      "Receiving objects: 100% (160/160), 501.71 KiB | 3.16 MiB/s, done.\n",
      "Resolving deltas: 100% (63/63), done.\n",
      "/workspace/GenerativeImage2Text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azfuse@ git+https://github.com/microsoft/azfuse.git (from -r requirements.txt (line 6))\n",
      "  Cloning https://github.com/microsoft/azfuse.git to /tmp/pip-install-t3dj47vb/azfuse_4c60889b673442eaa818efb2cdd23342\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/microsoft/azfuse.git /tmp/pip-install-t3dj47vb/azfuse_4c60889b673442eaa818efb2cdd23342\n",
      "  Resolved https://github.com/microsoft/azfuse.git to commit 3d2ff80d414e9a6cb6a4176d8c59eb70184ee31b\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pycocotools (from -r requirements.txt (line 1))\n",
      "  Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting pycocoevalcap (from -r requirements.txt (line 2))\n",
      "  Downloading pycocoevalcap-1.2-py3-none-any.whl (104.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm (from -r requirements.txt (line 3))\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (6.0.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.1.0+cu118)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.16.0+cu118)\n",
      "Collecting transformers (from -r requirements.txt (line 8))\n",
      "  Downloading transformers-4.38.1-py3-none-any.whl.metadata (131 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting boto3 (from -r requirements.txt (line 9))\n",
      "  Downloading boto3-1.34.49-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting matplotlib>=2.1.0 (from pycocotools->-r requirements.txt (line 1))\n",
      "  Downloading matplotlib-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools->-r requirements.txt (line 1)) (1.24.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (2023.4.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (2.1.0)\n",
      "Collecting azure-storage-blob (from azfuse@ git+https://github.com/microsoft/azfuse.git->-r requirements.txt (line 6))\n",
      "  Downloading azure_storage_blob-12.19.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting deprecated (from azfuse@ git+https://github.com/microsoft/azfuse.git->-r requirements.txt (line 6))\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from azfuse@ git+https://github.com/microsoft/azfuse.git->-r requirements.txt (line 6)) (5.9.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 7)) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 7)) (9.3.0)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers->-r requirements.txt (line 8))\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 8)) (23.2)\n",
      "Collecting regex!=2019.12.17 (from transformers->-r requirements.txt (line 8))\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.19,>=0.14 (from transformers->-r requirements.txt (line 8))\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers->-r requirements.txt (line 8))\n",
      "  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting botocore<1.35.0,>=1.34.49 (from boto3->-r requirements.txt (line 9))\n",
      "  Downloading botocore-1.34.49-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->-r requirements.txt (line 9))\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->-r requirements.txt (line 9))\n",
      "  Downloading s3transfer-0.10.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.49->boto3->-r requirements.txt (line 9)) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.49->boto3->-r requirements.txt (line 9)) (1.26.13)\n",
      "Collecting fsspec (from torch->-r requirements.txt (line 5))\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1))\n",
      "  Downloading contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1))\n",
      "  Downloading fonttools-4.49.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (159 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.1/159.1 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1))\n",
      "  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1)) (2.4.7)\n",
      "Collecting azure-core<2.0.0,>=1.28.0 (from azure-storage-blob->azfuse@ git+https://github.com/microsoft/azfuse.git->-r requirements.txt (line 6))\n",
      "  Downloading azure_core-1.30.0-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /usr/lib/python3/dist-packages (from azure-storage-blob->azfuse@ git+https://github.com/microsoft/azfuse.git->-r requirements.txt (line 6)) (3.4.8)\n",
      "Collecting isodate>=0.6.1 (from azure-storage-blob->azfuse@ git+https://github.com/microsoft/azfuse.git->-r requirements.txt (line 6))\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated->azfuse@ git+https://github.com/microsoft/azfuse.git->-r requirements.txt (line 6))\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 5)) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 7)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 7)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 7)) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /usr/lib/python3/dist-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob->azfuse@ git+https://github.com/microsoft/azfuse.git->-r requirements.txt (line 6)) (1.16.0)\n",
      "Collecting typing-extensions (from torch->-r requirements.txt (line 5))\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.2/426.2 kB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.38.1-py3-none-any.whl (8.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m150.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading boto3-1.34.49-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.34.49-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m150.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading matplotlib-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m152.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m121.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m118.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_storage_blob-12.19.0-py3-none-any.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading azure_core-1.30.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Downloading contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (310 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.7/310.7 kB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.49.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m118.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: azfuse\n",
      "  Building wheel for azfuse (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for azfuse: filename=azfuse-0.1-py3-none-any.whl size=19217 sha256=2c64e9a2fc029a6a80f6bb188d66096f9bb4e2bb7dcb5153871e1c0d1180142d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-1mad07ky/wheels/65/93/85/c58d017f4796af7b56ba47848a891bd909e56b1a6a02b1a97b\n",
      "Successfully built azfuse\n",
      "Installing collected packages: wrapt, typing-extensions, tqdm, safetensors, regex, kiwisolver, jmespath, isodate, fsspec, fonttools, cycler, contourpy, matplotlib, huggingface-hub, deprecated, botocore, azure-core, tokenizers, s3transfer, pycocotools, azure-storage-blob, transformers, pycocoevalcap, boto3, azfuse\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed azfuse-0.1 azure-core-1.30.0 azure-storage-blob-12.19.0 boto3-1.34.49 botocore-1.34.49 contourpy-1.2.0 cycler-0.12.1 deprecated-1.2.14 fonttools-4.49.0 fsspec-2024.2.0 huggingface-hub-0.20.3 isodate-0.6.1 jmespath-1.0.1 kiwisolver-1.4.5 matplotlib-3.8.3 pycocoevalcap-1.2 pycocotools-2.0.7 regex-2023.12.25 s3transfer-0.10.0 safetensors-0.4.2 tokenizers-0.15.2 tqdm-4.66.2 transformers-4.38.1 typing-extensions-4.10.0 wrapt-1.16.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "creating build/lib/generativeimage2text\n",
      "copying generativeimage2text/tsv_io.py -> build/lib/generativeimage2text\n",
      "copying generativeimage2text/trie_decoder.py -> build/lib/generativeimage2text\n",
      "copying generativeimage2text/train.py -> build/lib/generativeimage2text\n",
      "copying generativeimage2text/torch_common.py -> build/lib/generativeimage2text\n",
      "copying generativeimage2text/taxonomy.py -> build/lib/generativeimage2text\n",
      "copying generativeimage2text/process_image.py -> build/lib/generativeimage2text\n",
      "copying generativeimage2text/model.py -> build/lib/generativeimage2text\n",
      "copying generativeimage2text/inference.py -> build/lib/generativeimage2text\n",
      "copying generativeimage2text/data_prepare.py -> build/lib/generativeimage2text\n",
      "copying generativeimage2text/common.py -> build/lib/generativeimage2text\n",
      "copying generativeimage2text/__init__.py -> build/lib/generativeimage2text\n",
      "creating build/lib/generativeimage2text/layers\n",
      "copying generativeimage2text/layers/decoder.py -> build/lib/generativeimage2text/layers\n",
      "copying generativeimage2text/layers/__init__.py -> build/lib/generativeimage2text/layers\n",
      "creating build/lib/generativeimage2text/data_layer\n",
      "copying generativeimage2text/data_layer/transform.py -> build/lib/generativeimage2text/data_layer\n",
      "copying generativeimage2text/data_layer/builder.py -> build/lib/generativeimage2text/data_layer\n",
      "copying generativeimage2text/data_layer/__init__.py -> build/lib/generativeimage2text/data_layer\n",
      "creating build/lib/generativeimage2text/layers/bert\n",
      "copying generativeimage2text/layers/bert/modeling_utils.py -> build/lib/generativeimage2text/layers/bert\n",
      "copying generativeimage2text/layers/bert/modeling_bert.py -> build/lib/generativeimage2text/layers/bert\n",
      "copying generativeimage2text/layers/bert/file_utils.py -> build/lib/generativeimage2text/layers/bert\n",
      "copying generativeimage2text/layers/bert/activations.py -> build/lib/generativeimage2text/layers/bert\n",
      "copying generativeimage2text/layers/bert/__init__.py -> build/lib/generativeimage2text/layers/bert\n",
      "creating build/lib/generativeimage2text/layers/CLIP\n",
      "copying generativeimage2text/layers/CLIP/model.py -> build/lib/generativeimage2text/layers/CLIP\n",
      "copying generativeimage2text/layers/CLIP/clip.py -> build/lib/generativeimage2text/layers/CLIP\n",
      "copying generativeimage2text/layers/CLIP/__init__.py -> build/lib/generativeimage2text/layers/CLIP\n",
      "running develop\n",
      "/usr/local/lib/python3.10/dist-packages/setuptools/command/develop.py:40: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` and ``easy_install``.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  easy_install.initialize_options(self)\n",
      "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n",
      "running egg_info\n",
      "creating generativeimage2text.egg-info\n",
      "writing generativeimage2text.egg-info/PKG-INFO\n",
      "writing dependency_links to generativeimage2text.egg-info/dependency_links.txt\n",
      "writing requirements to generativeimage2text.egg-info/requires.txt\n",
      "writing top-level names to generativeimage2text.egg-info/top_level.txt\n",
      "writing manifest file 'generativeimage2text.egg-info/SOURCES.txt'\n",
      "reading manifest file 'generativeimage2text.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "adding license file 'LICENSE'\n",
      "writing manifest file 'generativeimage2text.egg-info/SOURCES.txt'\n",
      "running build_ext\n",
      "Creating /usr/local/lib/python3.10/dist-packages/generativeimage2text.egg-link (link to .)\n",
      "Adding generativeimage2text 0.1 to easy-install.pth file\n",
      "\n",
      "Installed /workspace/GenerativeImage2Text\n",
      "Processing dependencies for generativeimage2text==0.1\n",
      "Searching for boto3==1.34.49\n",
      "Best match: boto3 1.34.49\n",
      "Adding boto3 1.34.49 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for transformers==4.38.1\n",
      "Best match: transformers 4.38.1\n",
      "Adding transformers 4.38.1 to easy-install.pth file\n",
      "Installing transformers-cli script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for torchvision==0.16.0+cu118\n",
      "Best match: torchvision 0.16.0+cu118\n",
      "Adding torchvision 0.16.0+cu118 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for azfuse==0.1\n",
      "Best match: azfuse 0.1\n",
      "Adding azfuse 0.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for torch==2.1.0+cu118\n",
      "Best match: torch 2.1.0+cu118\n",
      "Adding torch 2.1.0+cu118 to easy-install.pth file\n",
      "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
      "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
      "Installing torchrun script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for PyYAML==6.0.1\n",
      "Best match: PyYAML 6.0.1\n",
      "Adding PyYAML 6.0.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for tqdm==4.66.2\n",
      "Best match: tqdm 4.66.2\n",
      "Adding tqdm 4.66.2 to easy-install.pth file\n",
      "Installing tqdm script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for pycocoevalcap==1.2\n",
      "Best match: pycocoevalcap 1.2\n",
      "Adding pycocoevalcap 1.2 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for pycocotools==2.0.7\n",
      "Best match: pycocotools 2.0.7\n",
      "Adding pycocotools 2.0.7 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for s3transfer==0.10.0\n",
      "Best match: s3transfer 0.10.0\n",
      "Adding s3transfer 0.10.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for jmespath==1.0.1\n",
      "Best match: jmespath 1.0.1\n",
      "Adding jmespath 1.0.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for botocore==1.34.49\n",
      "Best match: botocore 1.34.49\n",
      "Adding botocore 1.34.49 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for safetensors==0.4.2\n",
      "Best match: safetensors 0.4.2\n",
      "Adding safetensors 0.4.2 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for tokenizers==0.15.2\n",
      "Best match: tokenizers 0.15.2\n",
      "Adding tokenizers 0.15.2 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for requests==2.31.0\n",
      "Best match: requests 2.31.0\n",
      "Adding requests 2.31.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for regex==2023.12.25\n",
      "Best match: regex 2023.12.25\n",
      "Adding regex 2023.12.25 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for packaging==23.2\n",
      "Best match: packaging 23.2\n",
      "Adding packaging 23.2 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for numpy==1.24.1\n",
      "Best match: numpy 1.24.1\n",
      "Adding numpy 1.24.1 to easy-install.pth file\n",
      "Installing f2py script to /usr/local/bin\n",
      "Installing f2py3 script to /usr/local/bin\n",
      "Installing f2py3.10 script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for huggingface-hub==0.20.3\n",
      "Best match: huggingface-hub 0.20.3\n",
      "Adding huggingface-hub 0.20.3 to easy-install.pth file\n",
      "Installing huggingface-cli script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for filelock==3.9.0\n",
      "Best match: filelock 3.9.0\n",
      "Adding filelock 3.9.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for Pillow==9.3.0\n",
      "Best match: Pillow 9.3.0\n",
      "Adding Pillow 9.3.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for psutil==5.9.6\n",
      "Best match: psutil 5.9.6\n",
      "Adding psutil 5.9.6 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for Deprecated==1.2.14\n",
      "Best match: Deprecated 1.2.14\n",
      "Adding Deprecated 1.2.14 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for azure-storage-blob==12.19.0\n",
      "Best match: azure-storage-blob 12.19.0\n",
      "Adding azure-storage-blob 12.19.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for triton==2.1.0\n",
      "Best match: triton 2.1.0\n",
      "Adding triton 2.1.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for fsspec==2024.2.0\n",
      "Best match: fsspec 2024.2.0\n",
      "Adding fsspec 2024.2.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for Jinja2==3.1.2\n",
      "Best match: Jinja2 3.1.2\n",
      "Adding Jinja2 3.1.2 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for networkx==3.0\n",
      "Best match: networkx 3.0\n",
      "Adding networkx 3.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for sympy==1.12\n",
      "Best match: sympy 1.12\n",
      "Adding sympy 1.12 to easy-install.pth file\n",
      "Installing isympy script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for typing-extensions==4.10.0\n",
      "Best match: typing-extensions 4.10.0\n",
      "Adding typing-extensions 4.10.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for matplotlib==3.8.3\n",
      "Best match: matplotlib 3.8.3\n",
      "Adding matplotlib 3.8.3 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for urllib3==1.26.13\n",
      "Best match: urllib3 1.26.13\n",
      "Adding urllib3 1.26.13 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for python-dateutil==2.8.2\n",
      "Best match: python-dateutil 2.8.2\n",
      "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for certifi==2022.12.7\n",
      "Best match: certifi 2022.12.7\n",
      "Adding certifi 2022.12.7 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for idna==3.4\n",
      "Best match: idna 3.4\n",
      "Adding idna 3.4 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for charset-normalizer==2.1.1\n",
      "Best match: charset-normalizer 2.1.1\n",
      "Adding charset-normalizer 2.1.1 to easy-install.pth file\n",
      "Installing normalizer script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for wrapt==1.16.0\n",
      "Best match: wrapt 1.16.0\n",
      "Adding wrapt 1.16.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for isodate==0.6.1\n",
      "Best match: isodate 0.6.1\n",
      "Adding isodate 0.6.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for cryptography==3.4.8\n",
      "Best match: cryptography 3.4.8\n",
      "Adding cryptography 3.4.8 to easy-install.pth file\n",
      "\n",
      "Using /usr/lib/python3/dist-packages\n",
      "Searching for azure-core==1.30.0\n",
      "Best match: azure-core 1.30.0\n",
      "Adding azure-core 1.30.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for MarkupSafe==2.1.2\n",
      "Best match: MarkupSafe 2.1.2\n",
      "Adding MarkupSafe 2.1.2 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for mpmath==1.3.0\n",
      "Best match: mpmath 1.3.0\n",
      "Adding mpmath 1.3.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for pyparsing==2.4.7\n",
      "Best match: pyparsing 2.4.7\n",
      "Adding pyparsing 2.4.7 to easy-install.pth file\n",
      "\n",
      "Using /usr/lib/python3/dist-packages\n",
      "Searching for kiwisolver==1.4.5\n",
      "Best match: kiwisolver 1.4.5\n",
      "Adding kiwisolver 1.4.5 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for fonttools==4.49.0\n",
      "Best match: fonttools 4.49.0\n",
      "Adding fonttools 4.49.0 to easy-install.pth file\n",
      "Installing fonttools script to /usr/local/bin\n",
      "Installing pyftmerge script to /usr/local/bin\n",
      "Installing pyftsubset script to /usr/local/bin\n",
      "Installing ttx script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for cycler==0.12.1\n",
      "Best match: cycler 0.12.1\n",
      "Adding cycler 0.12.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for contourpy==1.2.0\n",
      "Best match: contourpy 1.2.0\n",
      "Adding contourpy 1.2.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.10/dist-packages\n",
      "Searching for six==1.16.0\n",
      "Best match: six 1.16.0\n",
      "Adding six 1.16.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/lib/python3/dist-packages\n",
      "Finished processing dependencies for generativeimage2text==0.1\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/microsoft/GenerativeImage2Text.git\n",
    "%cd GenerativeImage2Text/generativeimage2text\n",
    "!pip install -r requirements.txt\n",
    "!python setup.py build develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "0h-ee6jd7i5K"
   },
   "outputs": [],
   "source": [
    "from common import Config\n",
    "import json\n",
    "import os.path as op\n",
    "from common import qd_tqdm as tqdm\n",
    "from common import json_dump\n",
    "from common import pilimg_from_base64\n",
    "from torch_common import recursive_to_device\n",
    "from tsv_io import TSVFile, tsv_writer, tsv_reader\n",
    "from common import write_to_file\n",
    "import torch\n",
    "import PIL\n",
    "from pprint import pformat\n",
    "import logging\n",
    "from transformers import BertTokenizer\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "from PIL import Image\n",
    "from azfuse import File\n",
    "\n",
    "from common import init_logging\n",
    "from common import parse_general_args\n",
    "from tsv_io import load_from_yaml_file\n",
    "from torch_common import torch_load\n",
    "from torch_common import load_state_dict\n",
    "from torch_common import resize_2d_pos_embed\n",
    "from layers.CLIP import clip\n",
    "from layers.decoder import (TransformerDecoderTextualHead,\n",
    "                             AutoRegressiveBeamSearch, GeneratorWithBeamSearch)\n",
    "from layers.decoder import CaptioningModel\n",
    "from process_image import load_image_by_pil\n",
    "from data_layer.transform import RenameKey, SelectTransform\n",
    "from data_layer.transform import ImageTransform2Dict\n",
    "from data_layer.transform import get_inception_train_transform\n",
    "from data_layer.builder import collate_fn\n",
    "from model import get_git_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "5jiPKVCm7fHi"
   },
   "outputs": [],
   "source": [
    "def get_data(image_file, prefix, target, tokenizer, image_transform):\n",
    "    max_text_len = 40\n",
    "    prefix_encoding = tokenizer(\n",
    "        prefix, padding='do_not_pad',\n",
    "        add_special_tokens=False,\n",
    "        truncation=True, max_length=max_text_len)\n",
    "    target_encoding = tokenizer(\n",
    "        target, padding='do_not_pad',\n",
    "        add_special_tokens=False,\n",
    "        truncation=True, max_length=max_text_len)\n",
    "    need_predict = [0] * len(prefix_encoding['input_ids']) + [1] * len(target_encoding['input_ids'])\n",
    "    payload = prefix_encoding['input_ids'] + target_encoding['input_ids']\n",
    "    if len(payload) > max_text_len:\n",
    "        payload = payload[-(max_text_len - 2):]\n",
    "        need_predict = need_predict[-(max_text_len - 2):]\n",
    "    input_ids = [tokenizer.cls_token_id] + payload + [tokenizer.sep_token_id]\n",
    "    need_predict = [0] + need_predict + [1]\n",
    "\n",
    "    im = load_image_by_pil(image_file)\n",
    "\n",
    "    data = {\n",
    "        'caption_tokens': torch.tensor(input_ids),\n",
    "        #'caption_lengths': len(input_ids),\n",
    "        'need_predict': torch.tensor(need_predict),\n",
    "        'image': im,\n",
    "        # 'rect' field can be fed in 'caption', which tells the bounding box\n",
    "        # region of the image that is described by the caption. In this case,\n",
    "        # we can optionally crop the region.\n",
    "        'caption': {},\n",
    "        # this iteration can be used for crop-size selection so that all GPUs\n",
    "        # can process the image with the same input size\n",
    "        'iteration': 0,\n",
    "    }\n",
    "    data = image_transform(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_image_transform(cfg):\n",
    "    return get_multi_scale_image_transform(cfg, is_train=True)\n",
    "\n",
    "def get_default_mean():\n",
    "    return [0.485, 0.456, 0.406]\n",
    "\n",
    "def get_default_std():\n",
    "    return [0.229, 0.224, 0.225]\n",
    "\n",
    "def get_transform_image_norm(cfg, default=None):\n",
    "    if cfg.data_normalize == 'default':\n",
    "        normalize = transforms.Normalize(\n",
    "            mean=get_default_mean(), std=get_default_std())\n",
    "    elif cfg.data_normalize == 'clip':\n",
    "        # clip model\n",
    "        normalize = transforms.Normalize(\n",
    "            (0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
    "    else:\n",
    "        raise NotImplementedError(cfg.data_normalize)\n",
    "    return normalize\n",
    "\n",
    "def get_transform_vit_default(cfg, is_train):\n",
    "    default_normalize = transforms.Normalize(\n",
    "            mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    normalize = get_transform_image_norm(cfg, default_normalize)\n",
    "    transform = get_inception_train_transform(\n",
    "        bgr2rgb=True,\n",
    "        crop_size=cfg.train_crop_size,\n",
    "        normalize=normalize,\n",
    "        small_scale=cfg.input_small_scale,\n",
    "        no_color_jitter=cfg.no_color_jitter,\n",
    "        no_flip=cfg.no_flip,\n",
    "        no_aspect_dist=cfg.no_aspect_dist,\n",
    "        resize_crop=cfg.resize_crop,\n",
    "        max_size=cfg.train_max_size,\n",
    "        interpolation=cfg.interpolation or Image.BILINEAR,\n",
    "    )\n",
    "    return transform\n",
    "\n",
    "def get_transform_image(cfg, is_train):\n",
    "    train_transform = cfg.train_transform\n",
    "    if train_transform == 'vitp':\n",
    "        transform = get_transform_vit_default(\n",
    "            cfg, is_train=is_train)\n",
    "    else:\n",
    "        raise NotImplementedError(train_transform)\n",
    "    return transform\n",
    "\n",
    "class ImageTransform2Images(object):\n",
    "    def __init__(self, sep_transform, first_joint=None):\n",
    "        self.image_transform = sep_transform\n",
    "        self.first_joint = first_joint\n",
    "\n",
    "    def __call__(self, imgs):\n",
    "        if self.first_joint is not None:\n",
    "            imgs = self.first_joint(imgs)\n",
    "        return [self.image_transform(im) for im in imgs]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'ImageTransform2Images(image_transform={})'.format(\n",
    "            self.image_transform,\n",
    "        )\n",
    "\n",
    "def get_transform_images(cfg, is_train):\n",
    "    trans = get_transform_image(cfg, is_train)\n",
    "    trans = ImageTransform2Images(trans)\n",
    "    return trans\n",
    "\n",
    "def trans_select_for_crop_size(\n",
    "    data, train_crop_sizes,\n",
    "    iteration_multi=0,\n",
    "):\n",
    "    if iteration_multi <= 0:\n",
    "        if len(train_crop_sizes) == 1:\n",
    "            idx = 0\n",
    "        else:\n",
    "            idx = data['iteration'] % len(train_crop_sizes)\n",
    "    elif data['iteration'] <= iteration_multi:\n",
    "        idx = data['iteration'] % len(train_crop_sizes)\n",
    "    else:\n",
    "        idx = -1\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-26 16:17:22,883.883 305:1365122655.py:117 speed_test_forward_backward(): SelectTransform(ts=[Compose(\n",
      "    ImageTransform2Dict(image_transform=Compose(\n",
      "    RandomResizedCrop(size=(160, 160), scale=(0.8, 1.0), ratio=(1.0, 1.0), interpolation=bicubic, antialias=warn)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))\n",
      "))\n",
      "), Compose(\n",
      "    ImageTransform2Dict(image_transform=Compose(\n",
      "    RandomResizedCrop(size=(176, 176), scale=(0.8, 1.0), ratio=(1.0, 1.0), interpolation=bicubic, antialias=warn)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))\n",
      "))\n",
      "), Compose(\n",
      "    ImageTransform2Dict(image_transform=Compose(\n",
      "    RandomResizedCrop(size=(192, 192), scale=(0.8, 1.0), ratio=(1.0, 1.0), interpolation=bicubic, antialias=warn)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))\n",
      "))\n",
      "), Compose(\n",
      "    ImageTransform2Dict(image_transform=Compose(\n",
      "    RandomResizedCrop(size=(208, 208), scale=(0.8, 1.0), ratio=(1.0, 1.0), interpolation=bicubic, antialias=warn)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))\n",
      "))\n",
      "), Compose(\n",
      "    ImageTransform2Dict(image_transform=Compose(\n",
      "    RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0), ratio=(1.0, 1.0), interpolation=bicubic, antialias=warn)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))\n",
      "))\n",
      ")], selector=<function get_multi_scale_image_transform.<locals>.<lambda> at 0x7f89b53bb250>)\n",
      "2024-02-26 16:17:27,138.138 305:decoder.py:657    forward(): : iter=1, avg pos = 3.0091930966591462e-05, max loss = 0, min loss = 0\n",
      "2024-02-26 16:17:27,142.142 305:decoder.py:962 forward_one_ce(): {'num_has_image': 0, 'num_no_image': 0}\n",
      "2024-02-26 16:17:29,054.054 305:1365122655.py:143 speed_test_forward_backward(): speed = 4066.2747966070783\n",
      "2024-02-26 16:17:30,630.630 305:1365122655.py:143 speed_test_forward_backward(): speed = 4067.8202151841188\n",
      "2024-02-26 16:17:32,211.211 305:1365122655.py:143 speed_test_forward_backward(): speed = 4051.9213819755278\n",
      "2024-02-26 16:17:33,789.789 305:1365122655.py:143 speed_test_forward_backward(): speed = 4059.3637712133855\n",
      "2024-02-26 16:17:35,354.354 305:1365122655.py:143 speed_test_forward_backward(): speed = 4096.622594620399\n",
      "2024-02-26 16:17:36,924.924 305:1365122655.py:143 speed_test_forward_backward(): speed = 4079.928929851666\n",
      "2024-02-26 16:17:38,494.494 305:1365122655.py:143 speed_test_forward_backward(): speed = 4080.1900108132036\n",
      "2024-02-26 16:17:40,068.068 305:1365122655.py:143 speed_test_forward_backward(): speed = 4071.328257686499\n",
      "2024-02-26 16:17:41,633.633 305:1365122655.py:143 speed_test_forward_backward(): speed = 4094.248873963361\n",
      "2024-02-26 16:17:42,865.865 305:decoder.py:657    forward(): : iter=101, avg pos = 3.013218338310253e-05, max loss = 11.075187683105469, min loss = -3.1723226129543036e-05\n",
      "2024-02-26 16:17:43,205.205 305:1365122655.py:143 speed_test_forward_backward(): speed = 4074.5559829091612\n",
      "2024-02-26 16:17:44,780.780 305:1365122655.py:143 speed_test_forward_backward(): speed = 4065.6269083507004\n",
      "2024-02-26 16:17:46,353.353 305:1365122655.py:143 speed_test_forward_backward(): speed = 4073.9957234765775\n",
      "2024-02-26 16:17:47,922.922 305:1365122655.py:143 speed_test_forward_backward(): speed = 4081.1465594883853\n",
      "2024-02-26 16:17:49,493.493 305:1365122655.py:143 speed_test_forward_backward(): speed = 4075.7308016529128\n",
      "2024-02-26 16:17:51,065.065 305:1365122655.py:143 speed_test_forward_backward(): speed = 4074.908542986049\n",
      "2024-02-26 16:17:52,638.638 305:1365122655.py:143 speed_test_forward_backward(): speed = 4071.838988836838\n",
      "2024-02-26 16:17:54,211.211 305:1365122655.py:143 speed_test_forward_backward(): speed = 4074.13731975386\n",
      "2024-02-26 16:17:55,784.784 305:1365122655.py:143 speed_test_forward_backward(): speed = 4071.595032339423\n",
      "2024-02-26 16:17:57,356.356 305:1365122655.py:143 speed_test_forward_backward(): speed = 4072.7434269308424\n",
      "2024-02-26 16:17:58,591.591 305:decoder.py:657    forward(): : iter=201, avg pos = 2.9729324523941614e-05, max loss = 11.021800994873047, min loss = -3.198703416273929e-05\n",
      "2024-02-26 16:17:58,595.595 305:decoder.py:962 forward_one_ce(): {'num_has_image': 200, 'num_no_image': 0}\n",
      "2024-02-26 16:17:58,933.933 305:1365122655.py:143 speed_test_forward_backward(): speed = 4060.636107507932\n",
      "2024-02-26 16:18:00,508.508 305:1365122655.py:143 speed_test_forward_backward(): speed = 4070.1436325297377\n",
      "2024-02-26 16:18:02,082.082 305:1365122655.py:143 speed_test_forward_backward(): speed = 4067.881242649344\n",
      "2024-02-26 16:18:03,657.657 305:1365122655.py:143 speed_test_forward_backward(): speed = 4067.0485914780224\n",
      "2024-02-26 16:18:05,231.231 305:1365122655.py:143 speed_test_forward_backward(): speed = 4069.9788643772267\n",
      "2024-02-26 16:18:06,810.810 305:1365122655.py:143 speed_test_forward_backward(): speed = 4055.888564222269\n",
      "2024-02-26 16:18:08,388.388 305:1365122655.py:143 speed_test_forward_backward(): speed = 4061.935671311148\n",
      "2024-02-26 16:18:09,967.967 305:1365122655.py:143 speed_test_forward_backward(): speed = 4057.124996750497\n",
      "2024-02-26 16:18:11,547.547 305:1365122655.py:143 speed_test_forward_backward(): speed = 4055.0877680626977\n",
      "2024-02-26 16:18:13,126.126 305:1365122655.py:143 speed_test_forward_backward(): speed = 4059.7861573830482\n",
      "2024-02-26 16:18:14,361.361 305:decoder.py:657    forward(): : iter=301, avg pos = 2.9677165002794936e-05, max loss = 11.081059455871582, min loss = -3.147116876789369e-05\n",
      "2024-02-26 16:18:14,707.707 305:1365122655.py:143 speed_test_forward_backward(): speed = 4052.7197041844993\n",
      "2024-02-26 16:18:16,285.285 305:1365122655.py:143 speed_test_forward_backward(): speed = 4059.8045773846425\n",
      "2024-02-26 16:18:17,866.866 305:1365122655.py:143 speed_test_forward_backward(): speed = 4055.3732490096318\n",
      "2024-02-26 16:18:19,445.445 305:1365122655.py:143 speed_test_forward_backward(): speed = 4059.851856153826\n",
      "2024-02-26 16:18:21,025.025 305:1365122655.py:143 speed_test_forward_backward(): speed = 4054.410983525467\n",
      "2024-02-26 16:18:22,605.605 305:1365122655.py:143 speed_test_forward_backward(): speed = 4057.207166221652\n",
      "2024-02-26 16:18:24,184.184 305:1365122655.py:143 speed_test_forward_backward(): speed = 4057.735828521329\n",
      "2024-02-26 16:18:25,763.763 305:1365122655.py:143 speed_test_forward_backward(): speed = 4056.7111339745334\n",
      "2024-02-26 16:18:27,343.343 305:1365122655.py:143 speed_test_forward_backward(): speed = 4053.848291326273\n",
      "2024-02-26 16:18:28,920.920 305:1365122655.py:143 speed_test_forward_backward(): speed = 4062.2590016939985\n",
      "2024-02-26 16:18:30,157.157 305:decoder.py:657    forward(): : iter=401, avg pos = 2.9785498554701917e-05, max loss = 10.992966651916504, min loss = -3.1936018785927445e-05\n",
      "2024-02-26 16:18:30,160.160 305:decoder.py:962 forward_one_ce(): {'num_has_image': 400, 'num_no_image': 0}\n",
      "2024-02-26 16:18:30,504.504 305:1365122655.py:143 speed_test_forward_backward(): speed = 4044.400811666103\n",
      "2024-02-26 16:18:32,085.085 305:1365122655.py:143 speed_test_forward_backward(): speed = 4053.5746552764786\n",
      "2024-02-26 16:18:33,667.667 305:1365122655.py:143 speed_test_forward_backward(): speed = 4050.2743457007805\n",
      "2024-02-26 16:18:35,254.254 305:1365122655.py:143 speed_test_forward_backward(): speed = 4037.436349965805\n",
      "2024-02-26 16:18:36,832.832 305:1365122655.py:143 speed_test_forward_backward(): speed = 4059.9464169958005\n",
      "2024-02-26 16:18:38,411.411 305:1365122655.py:143 speed_test_forward_backward(): speed = 4057.0931109864387\n",
      "2024-02-26 16:18:39,986.986 305:1365122655.py:143 speed_test_forward_backward(): speed = 4066.9118005767464\n",
      "2024-02-26 16:18:41,569.569 305:1365122655.py:143 speed_test_forward_backward(): speed = 4047.3369733446293\n",
      "2024-02-26 16:18:43,151.151 305:1365122655.py:143 speed_test_forward_backward(): speed = 4050.3024575781574\n",
      "2024-02-26 16:18:44,731.731 305:1365122655.py:143 speed_test_forward_backward(): speed = 4053.8342107174717\n",
      "2024-02-26 16:18:45,967.967 305:decoder.py:657    forward(): : iter=501, avg pos = 2.9988486858201213e-05, max loss = 11.049280166625977, min loss = -3.178522456437349e-05\n",
      "2024-02-26 16:18:46,308.308 305:1365122655.py:143 speed_test_forward_backward(): speed = 4060.6096947411766\n",
      "2024-02-26 16:18:47,894.894 305:1365122655.py:143 speed_test_forward_backward(): speed = 4040.7510408752883\n",
      "2024-02-26 16:18:49,472.472 305:1365122655.py:143 speed_test_forward_backward(): speed = 4057.3206146179978\n",
      "2024-02-26 16:18:51,055.055 305:1365122655.py:143 speed_test_forward_backward(): speed = 4049.962085654135\n",
      "2024-02-26 16:18:52,636.636 305:1365122655.py:143 speed_test_forward_backward(): speed = 4052.86166106729\n",
      "2024-02-26 16:18:54,215.215 305:1365122655.py:143 speed_test_forward_backward(): speed = 4053.9688988086923\n",
      "2024-02-26 16:18:55,795.795 305:1365122655.py:143 speed_test_forward_backward(): speed = 4055.1269733653835\n",
      "2024-02-26 16:18:57,377.377 305:1365122655.py:143 speed_test_forward_backward(): speed = 4049.095831430228\n",
      "2024-02-26 16:18:58,956.956 305:1365122655.py:143 speed_test_forward_backward(): speed = 4058.0891645794354\n",
      "2024-02-26 16:19:00,538.538 305:1365122655.py:143 speed_test_forward_backward(): speed = 4050.8170961137666\n",
      "2024-02-26 16:19:01,775.775 305:decoder.py:657    forward(): : iter=601, avg pos = 3.0184635761543177e-05, max loss = 11.08073902130127, min loss = -3.167390241287649e-05\n",
      "2024-02-26 16:19:01,778.778 305:decoder.py:962 forward_one_ce(): {'num_has_image': 600, 'num_no_image': 0}\n",
      "2024-02-26 16:19:02,122.122 305:1365122655.py:143 speed_test_forward_backward(): speed = 4043.5491164566074\n",
      "2024-02-26 16:19:03,704.704 305:1365122655.py:143 speed_test_forward_backward(): speed = 4049.7800071088086\n",
      "2024-02-26 16:19:05,285.285 305:1365122655.py:143 speed_test_forward_backward(): speed = 4050.7345740062296\n",
      "2024-02-26 16:19:06,865.865 305:1365122655.py:143 speed_test_forward_backward(): speed = 4054.797427386569\n",
      "2024-02-26 16:19:08,447.447 305:1365122655.py:143 speed_test_forward_backward(): speed = 4048.5333922937507\n",
      "2024-02-26 16:19:10,026.026 305:1365122655.py:143 speed_test_forward_backward(): speed = 4056.130642134851\n",
      "2024-02-26 16:19:11,608.608 305:1365122655.py:143 speed_test_forward_backward(): speed = 4049.3059465043298\n",
      "2024-02-26 16:19:13,189.189 305:1365122655.py:143 speed_test_forward_backward(): speed = 4050.5982670739063\n",
      "2024-02-26 16:19:14,770.770 305:1365122655.py:143 speed_test_forward_backward(): speed = 4051.6773600318297\n",
      "2024-02-26 16:19:16,352.352 305:1365122655.py:143 speed_test_forward_backward(): speed = 4049.8667673266596\n",
      "2024-02-26 16:19:17,589.589 305:decoder.py:657    forward(): : iter=701, avg pos = 2.996500006702263e-05, max loss = 11.131706237792969, min loss = -3.131445191684179e-05\n",
      "2024-02-26 16:19:17,935.935 305:1365122655.py:143 speed_test_forward_backward(): speed = 4046.427923779829\n",
      "2024-02-26 16:19:19,514.514 305:1365122655.py:143 speed_test_forward_backward(): speed = 4057.789806436945\n",
      "2024-02-26 16:19:21,098.098 305:1365122655.py:143 speed_test_forward_backward(): speed = 4045.7460996638283\n",
      "2024-02-26 16:19:22,671.671 305:1365122655.py:143 speed_test_forward_backward(): speed = 4071.469668599753\n",
      "2024-02-26 16:19:24,249.249 305:1365122655.py:143 speed_test_forward_backward(): speed = 4059.8199275136553\n",
      "2024-02-26 16:19:25,832.832 305:1365122655.py:143 speed_test_forward_backward(): speed = 4047.044080570166\n",
      "2024-02-26 16:19:27,407.407 305:1365122655.py:143 speed_test_forward_backward(): speed = 4065.5647170133375\n",
      "2024-02-26 16:19:28,990.990 305:1365122655.py:143 speed_test_forward_backward(): speed = 4046.377907403547\n",
      "2024-02-26 16:19:30,565.565 305:1365122655.py:143 speed_test_forward_backward(): speed = 4070.283109631271\n",
      "2024-02-26 16:19:32,143.143 305:1365122655.py:143 speed_test_forward_backward(): speed = 4060.240566216817\n",
      "2024-02-26 16:19:33,386.386 305:decoder.py:657    forward(): : iter=801, avg pos = 2.984359161928296e-05, max loss = 11.284707069396973, min loss = -3.1584189855493605e-05\n",
      "2024-02-26 16:19:33,389.389 305:decoder.py:962 forward_one_ce(): {'num_has_image': 800, 'num_no_image': 0}\n",
      "2024-02-26 16:19:33,729.729 305:1365122655.py:143 speed_test_forward_backward(): speed = 4038.3735627981932\n",
      "2024-02-26 16:19:35,308.308 305:1365122655.py:143 speed_test_forward_backward(): speed = 4059.977733570265\n",
      "2024-02-26 16:19:36,886.886 305:1365122655.py:143 speed_test_forward_backward(): speed = 4058.236406099008\n",
      "2024-02-26 16:19:38,469.469 305:1365122655.py:143 speed_test_forward_backward(): speed = 4047.8282741157777\n",
      "2024-02-26 16:19:40,047.047 305:1365122655.py:143 speed_test_forward_backward(): speed = 4058.3885668946964\n",
      "2024-02-26 16:19:41,625.625 305:1365122655.py:143 speed_test_forward_backward(): speed = 4062.0051276797712\n",
      "2024-02-26 16:19:43,201.201 305:1365122655.py:143 speed_test_forward_backward(): speed = 4065.4766671856382\n",
      "2024-02-26 16:19:44,784.784 305:1365122655.py:143 speed_test_forward_backward(): speed = 4048.0223860452757\n",
      "2024-02-26 16:19:46,358.358 305:1365122655.py:143 speed_test_forward_backward(): speed = 4068.521833284782\n",
      "2024-02-26 16:19:47,936.936 305:1365122655.py:143 speed_test_forward_backward(): speed = 4059.7216886937467\n",
      "2024-02-26 16:19:49,175.175 305:decoder.py:657    forward(): : iter=901, avg pos = 2.9742728656856343e-05, max loss = 11.152774810791016, min loss = -3.151930286549032e-05\n",
      "2024-02-26 16:19:49,517.517 305:1365122655.py:143 speed_test_forward_backward(): speed = 4052.576533608542\n",
      "2024-02-26 16:19:51,100.100 305:1365122655.py:143 speed_test_forward_backward(): speed = 4046.756720738909\n",
      "2024-02-26 16:19:52,675.675 305:1365122655.py:143 speed_test_forward_backward(): speed = 4066.776867216821\n",
      "2024-02-26 16:19:54,254.254 305:1365122655.py:143 speed_test_forward_backward(): speed = 4059.6559941357514\n",
      "2024-02-26 16:19:55,832.832 305:1365122655.py:143 speed_test_forward_backward(): speed = 4060.5642410168102\n",
      "2024-02-26 16:19:57,411.411 305:1365122655.py:143 speed_test_forward_backward(): speed = 4056.4763427142825\n",
      "2024-02-26 16:19:58,995.995 305:1365122655.py:143 speed_test_forward_backward(): speed = 4043.666066222404\n",
      "2024-02-26 16:20:00,569.569 305:1365122655.py:143 speed_test_forward_backward(): speed = 4071.976729087306\n",
      "2024-02-26 16:20:02,147.147 305:1365122655.py:143 speed_test_forward_backward(): speed = 4059.503124376183\n",
      "2024-02-26 16:20:03,726.726 305:1365122655.py:143 speed_test_forward_backward(): speed = 4055.512941027879\n",
      "2024-02-26 16:20:04,965.965 305:decoder.py:657    forward(): : iter=1001, avg pos = 2.9774555514450185e-05, max loss = 11.16360855102539, min loss = -3.1799609132576734e-05\n",
      "2024-02-26 16:20:04,968.968 305:decoder.py:962 forward_one_ce(): {'num_has_image': 1000, 'num_no_image': 0}\n",
      "2024-02-26 16:20:05,308.308 305:1365122655.py:143 speed_test_forward_backward(): speed = 4049.180729953961\n",
      "2024-02-26 16:20:06,887.887 305:1365122655.py:143 speed_test_forward_backward(): speed = 4058.250517305684\n",
      "2024-02-26 16:20:08,465.465 305:1365122655.py:143 speed_test_forward_backward(): speed = 4058.5033085889054\n",
      "2024-02-26 16:20:10,048.048 305:1365122655.py:143 speed_test_forward_backward(): speed = 4046.7908845261145\n",
      "2024-02-26 16:20:11,621.621 305:1365122655.py:143 speed_test_forward_backward(): speed = 4069.9819498005836\n",
      "2024-02-26 16:20:13,200.200 305:1365122655.py:143 speed_test_forward_backward(): speed = 4057.6260369651695\n",
      "2024-02-26 16:20:14,778.778 305:1365122655.py:143 speed_test_forward_backward(): speed = 4058.829161285094\n",
      "2024-02-26 16:20:16,357.357 305:1365122655.py:143 speed_test_forward_backward(): speed = 4058.274445228242\n"
     ]
    }
   ],
   "source": [
    "def get_multi_scale_image_transform(cfg, is_train, get_one=get_transform_image):\n",
    "    def get_multi_res_transform(s):\n",
    "        old = cfg.train_crop_size if is_train else cfg.test_crop_size\n",
    "        all_t = []\n",
    "        multi_res_factors = cfg.multi_res_factors or []\n",
    "        for i, f in enumerate(multi_res_factors):\n",
    "            if is_train:\n",
    "                cfg.train_crop_size = s // f\n",
    "            else:\n",
    "                cfg.test_crop_size = s // f\n",
    "            key = 'image_{}'.format(i)\n",
    "            all_t.append(RenameKey({'image': key}, not_delete_origin=True))\n",
    "            t = get_one(cfg, is_train)\n",
    "            t = ImageTransform2Dict(t, key=key)\n",
    "            all_t.append(t)\n",
    "        # get_one depends on train_crop_size\n",
    "        if is_train:\n",
    "            cfg.train_crop_size = s\n",
    "        else:\n",
    "            cfg.test_crop_size = s\n",
    "        t = get_one(cfg, is_train)\n",
    "        t = ImageTransform2Dict(t)\n",
    "        all_t.append(t)\n",
    "        if is_train:\n",
    "            cfg.train_crop_size = old\n",
    "        else:\n",
    "            cfg.test_crop_size = old\n",
    "        return transforms.Compose(all_t)\n",
    "\n",
    "    if is_train:\n",
    "        if cfg.min_size_range32 is None:\n",
    "            train_crop_sizes = [cfg.train_crop_size]\n",
    "        else:\n",
    "            train_crop_sizes = list(range(\n",
    "                cfg.min_size_range32[0],\n",
    "                cfg.min_size_range32[1] + cfg.patch_size - 1, cfg.patch_size,\n",
    "            ))\n",
    "    else:\n",
    "        train_crop_sizes = [cfg.test_crop_size]\n",
    "\n",
    "    crop_trans = []\n",
    "    for s in train_crop_sizes:\n",
    "        t = get_multi_res_transform(s)\n",
    "        crop_trans.append(t)\n",
    "    iteration_multi = 0\n",
    "    image_transform = SelectTransform(\n",
    "        crop_trans,\n",
    "        lambda d: trans_select_for_crop_size(\n",
    "            d, train_crop_sizes, iteration_multi))\n",
    "    return image_transform\n",
    "\n",
    "def forward_backward_example(image_files, captions, prefixs=None):\n",
    "    if prefixs is None:\n",
    "        prefixs = [''] * len(captions)\n",
    "    cfg = {\n",
    "        'crop_region_extend_in_datatransform': 4,\n",
    "        'data_normalize': 'clip',\n",
    "        'train_crop_size': 224,\n",
    "        'input_small_scale': 0.8,\n",
    "        'no_color_jitter': True,\n",
    "        'no_flip': True,\n",
    "        'no_aspect_dist': True,\n",
    "        'interpolation': 'bicubic',\n",
    "        'min_size_range32': [160, 224],\n",
    "        'patch_size': 16,\n",
    "        'train_transform': 'vitp',\n",
    "    }\n",
    "    cfg = Config(cfg, {})\n",
    "    all_data = []\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "    image_transform = get_image_transform(cfg)\n",
    "    for image_file, prefix, target in zip(image_files, prefixs, captions):\n",
    "        data = get_data(image_file, prefix, target,\n",
    "                        tokenizer, image_transform)\n",
    "        all_data.append(data)\n",
    "    data = collate_fn(all_data)\n",
    "    logging.info(image_transform)\n",
    "    data = recursive_to_device(data, 'cuda')\n",
    "\n",
    "    param = {}\n",
    "    model = get_git_model(tokenizer, param)\n",
    "    model.train()\n",
    "    model.cuda()\n",
    "    loss_dict = model(data)\n",
    "    loss = sum(loss_dict.values())\n",
    "    loss.backward()\n",
    "    logging.info(loss)\n",
    "\n",
    "def speed_test_forward_backward():\n",
    "    duplicate = 32\n",
    "    image_files = ['/workspace/GenerativeImage2Text/aux_data/images/1.jpg', '/workspace/GenerativeImage2Text/aux_data/images/2.jpg'] * duplicate\n",
    "    captions = ['a couple of boats in a large body of water.', 'a view of a mountain with a tree'] * duplicate\n",
    "\n",
    "    prefixs = [''] * len(captions)\n",
    "    cfg = {\n",
    "        'crop_region_extend_in_datatransform': 4,\n",
    "        'data_normalize': 'clip',\n",
    "        'train_crop_size': 224,\n",
    "        'input_small_scale': 0.8,\n",
    "        'no_color_jitter': True,\n",
    "        'no_flip': True,\n",
    "        'no_aspect_dist': True,\n",
    "        'interpolation': 'bicubic',\n",
    "        'min_size_range32': [160, 224],\n",
    "        'patch_size': 16,\n",
    "        'train_transform': 'vitp',\n",
    "    }\n",
    "    cfg = Config(cfg, {})\n",
    "    all_data = []\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "    image_transform = get_image_transform(cfg)\n",
    "    for image_file, prefix, target in zip(image_files, prefixs, captions):\n",
    "        data = get_data(image_file, prefix, target,\n",
    "                        tokenizer, image_transform)\n",
    "        all_data.append(data)\n",
    "    data = collate_fn(all_data)\n",
    "    logging.info(image_transform)\n",
    "    data = recursive_to_device(data, 'cuda')\n",
    "    data['image'] = data['image'].to(torch.float16)\n",
    "\n",
    "    param = {}\n",
    "    model = get_git_model(tokenizer, param)\n",
    "    model.train()\n",
    "    model.cuda()\n",
    "    model.half()\n",
    "\n",
    "    # warmup\n",
    "    for _ in range(2):\n",
    "        loss_dict = model(data)\n",
    "        loss = sum(loss_dict.values())\n",
    "        loss.backward()\n",
    "\n",
    "    import time\n",
    "    start = time.time()\n",
    "    for iteration in range(50000):\n",
    "        loss_dict = model(data)\n",
    "        loss = sum(loss_dict.values())\n",
    "        loss.backward()\n",
    "        if (iteration % 10) == 0:\n",
    "            end = time.time()\n",
    "            speed = data['image'].shape[0] * 100 / (end - start)\n",
    "            if iteration > 0:\n",
    "                logging.info('speed = {}'.format(speed))\n",
    "            start = time.time()\n",
    "\n",
    "    logging.info(loss)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    init_logging()\n",
    "    speed_test_forward_backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5RCkApMEVoyY",
    "outputId": "b0b6872d-5879-4ae1-bcd1-dff19ff3a8a2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# single image, captioning\n",
    "!AZFUSE_TSV_USE_FUSE=1 python -m generativeimage2text.inference -p \"{'type': 'test_git_inference_single_image', \\\n",
    "      'image_path': '/workspace/GenerativeImage2Text/aux_data/images/1.jpg', \\\n",
    "      'model_name': 'GIT_BASE', \\\n",
    "      'prefix': '', \\\n",
    "}\"\n",
    "# single image, question answering\n",
    "!AZFUSE_TSV_USE_FUSE=1 python -m generativeimage2text.inference -p \"{'type': 'test_git_inference_single_image', \\\n",
    "      'image_path': '/workspace/GenerativeImage2Text/aux_data/images/1.jpg', \\\n",
    "      'model_name': 'GIT_BASE_VQAv2', \\\n",
    "      'prefix': 'what is it?', \\\n",
    "}\"\n",
    "# multiple images, captioning\n",
    "!AZFUSE_TSV_USE_FUSE=1 python -m generativeimage2text.inference -p \"{'type': 'test_git_inference_single_image', \\\n",
    "      'image_path': ['/workspace/GenerativeImage2Text/aux_data/images/1.jpg', '/workspace/GenerativeImage2Text/aux_data/images/1.jpg', '/workspace/GenerativeImage2Text/aux_data/images/1.jpg', '/workspace/GenerativeImage2Text/aux_data/images/1.jpg', '/workspace/GenerativeImage2Text/aux_data/images/1.jpg', '/workspace/GenerativeImage2Text/aux_data/images/1.jpg'], \\\n",
    "      'model_name': 'GIT_BASE_VATEX', \\\n",
    "      'prefix': '', \\\n",
    "}\"\n",
    "# multiple images, question answering\n",
    "!AZFUSE_TSV_USE_FUSE=1 python -m generativeimage2text.inference -p \"{'type': 'test_git_inference_single_image', \\\n",
    "      'image_path': ['/workspace/GenerativeImage2Text/aux_data/images/1.jpg', '/workspace/GenerativeImage2Text/aux_data/images/1.jpg', '/workspace/GenerativeImage2Text/aux_data/images/1.jpg', '/workspace/GenerativeImage2Text/aux_data/images/1.jpg', '/workspace/GenerativeImage2Text/aux_data/images/1.jpg', '/workspace/GenerativeImage2Text/aux_data/images/1.jpg'], \\\n",
    "      'model_name': 'GIT_BASE_MSRVTT_QA', \\\n",
    "      'prefix': 'what is it?', \\\n",
    "}\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
